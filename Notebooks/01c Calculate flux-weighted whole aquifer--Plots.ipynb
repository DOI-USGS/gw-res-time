{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to get residence-time distribution (RTD) for the entire aquifer from an existing MODFLOW model. It is possible to read in any group or label from a 3D array and make RTDs for those groups. The approach is to \n",
    "* read an existing model\n",
    "* create flux-weighted particle starting locations in every cell\n",
    "* run MODPATH and read endpoints\n",
    "* fit parametric distributions\n",
    "\n",
    "This notebook fits parametric distributions. Another notebook creates flux-weighted particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "__author__ = 'Jeff Starn'\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import flopy as fp\n",
    "import imeth\n",
    "import fit_parametric_distributions\n",
    "import pandas as pd\n",
    "import gdal\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.interpolate import griddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set user-defined variables\n",
    "\n",
    "MODFLOW and MODPATH use elapsed time and are not aware of calendar time. To place MODFLOW/MODPATH elapsed time on the calendar, two calendar dates were specified at the top of the notebook: the beginning of the first stress period (`mf_start_date`) and when particles are to be released (`mp_release_date`). The latter date could be used in many ways, for example to represent a sampling date, or it could be looped over to create a time-lapse set of ages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through home directory to get list of name files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.mkdir(dst)\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2020' \n",
    "\n",
    "logtransform = False\n",
    "\n",
    "weight_scheme = 'flow'\n",
    "# weight_scheme = 'volume'\n",
    "\n",
    "# dist_list = [ss.invgauss, ss.gamma, ss.weibull_min]\n",
    "dist_list = [ss.weibull_min]\n",
    "\n",
    "por = 0.20\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    mod_list.append(mod)\n",
    "                    dir_list.append(dirpath)\n",
    "                    i += 1\n",
    "print('    {} models read'.format(i))\n",
    "\n",
    "model_area = Dropdown(\n",
    "    options=mod_list,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_area.value\n",
    "model_ws = [item for item in dir_list if model in item][0]\n",
    "nam_file = '{}.nam'.format(model)\n",
    "print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create names and path for model workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedures in this notebook can be run from the notebook or from a batch file by downloading the notebook as a Python script and uncommenting the following code and commenting out the following block. The remainder of the script has to be indented to be included in the loop.  This may require familiarity with Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for pth in dir_list:\n",
    "#     model = os.path.normpath(pth).split(os.sep)[2]\n",
    "#     model_ws = [item for item in dir_list if model in item][0]\n",
    "#     nam_file = '{}.nam'.format(model)\n",
    "#     print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Reading model information')\n",
    "\n",
    "fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                               load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "dis = fpmg.get_package('DIS')\n",
    "bas = fpmg.get_package('BAS6')\n",
    "upw = fpmg.get_package('UPW')\n",
    "oc = fpmg.get_package('OC')\n",
    "\n",
    "delr = dis.delr\n",
    "delc = dis.delc\n",
    "nlay = dis.nlay\n",
    "nrow = dis.nrow\n",
    "ncol = dis.ncol\n",
    "bot = dis.getbotm()\n",
    "top = dis.gettop()\n",
    "\n",
    "hnoflo = bas.hnoflo\n",
    "ibound = np.asarray(bas.ibound.get_value())\n",
    "hdry = upw.hdry\n",
    "\n",
    "print ('   ... done') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of time in MODFLOW/MODPATH\n",
    "\n",
    "There are several time-related concepts used in MODPATH.\n",
    "* `simulation time` is the elapsed time in model time units from the beginning of the first stress period\n",
    "* `reference time` is an arbitrary value of `simulation time` that is between the beginning and ending of `simulation time`\n",
    "* `tracking time` is the elapsed time relative to `reference time`. It is always positive regardless of whether particles are tracked forward or backward\n",
    "* `release time` is when a particle is released and is specified in `tracking time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup dictionaries of the MODFLOW units for proper labeling of figures.\n",
    "lenunit = {0:'undefined units', 1:'feet', 2:'meters', 3:'centimeters'}\n",
    "timeunit = {0:'undefined', 1:'second', 2:'minute', 3:'hour', 4:'day', 5:'year'}\n",
    "\n",
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days, so enter conversion to days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert string representation of dates into Python datetime objects\n",
    "mf_start_date = dt.datetime.strptime(mf_start_date_str , '%m/%d/%Y')\n",
    "mp_release_date = dt.datetime.strptime(mp_release_date_str , '%m/%d/%Y')\n",
    "\n",
    "# convert simulation time to days from the units specified in the MODFLOW DIS file\n",
    "sim_time = np.append(0, dis.get_totim())\n",
    "sim_time /= time_dict[dis.itmuni]\n",
    "\n",
    "# make a list of simulation time formatted as calendar dates\n",
    "date_list = [mf_start_date + dt.timedelta(days = item) for item in sim_time]\n",
    "\n",
    "# reference time and date are set to the end of the last stress period\n",
    "ref_time = sim_time[-1]\n",
    "ref_date = date_list[-1]\n",
    "\n",
    "# release time is calculated in tracking time (for particle release) and \n",
    "# in simulation time (for identifying head and budget components)\n",
    "release_time_trk = np.abs((ref_date - mp_release_date).days)\n",
    "release_time_sim = (mp_release_date - mf_start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, fpmg.namefile)\n",
    "name_file_df = pd.read_table(src, header=None, comment='#', delim_whitespace=True, \n",
    "              names=['package', 'unit', 'filename', 'type'])\n",
    "\n",
    "name_file_df['package'] = name_file_df.package.str.lower()\n",
    "name_file_df.set_index('unit', inplace=True)\n",
    "\n",
    "head_file_name = name_file_df.loc[oc.iuhead, 'filename']\n",
    "bud_file_name = name_file_df.loc[oc.get_budgetunit(), 'filename']\n",
    "\n",
    "src = os.path.join(model_ws, bud_file_name)\n",
    "bud_obj = fp.utils.CellBudgetFile(src)\n",
    "all_bud_df = pd.DataFrame(bud_obj.recordarray)\n",
    "\n",
    "# convert to zero base\n",
    "all_bud_df['kper'] = all_bud_df['kper'] - 1\n",
    "all_bud_df['kstp'] = all_bud_df['kstp'] - 1\n",
    "\n",
    "# add calendar date (not used at this time)\n",
    "all_bud_df['date'] = mf_start_date + pd.to_timedelta(all_bud_df.totim, unit='days')\n",
    "\n",
    "# group by period and step\n",
    "kdf = all_bud_df.groupby(['kper', 'kstp']).median()\n",
    "\n",
    "# find the latest group index that includes the release date\n",
    "idx = kdf.loc[(kdf.totim >= release_time_sim).idxmax(), :].name\n",
    "\n",
    "# switch period and step \n",
    "kstpkper = tuple(item for item in idx[-1::-1])\n",
    "\n",
    "# extract the budget records for the specified period and step\n",
    "bud_df = all_bud_df.query('kstp=={} and kper=={}'.format(*kstpkper)).copy()\n",
    "\n",
    "bud_df.loc[:, 'per_num'] = bud_df.totim.factorize()[0]\n",
    "num_rec = bud_df.shape[0]\n",
    "\n",
    "src = os.path.join(model_ws, head_file_name)\n",
    "hd_obj = fp.utils.HeadFile(src)\n",
    "head_df = pd.DataFrame(hd_obj.recordarray)\n",
    "\n",
    "heads = hd_obj.get_data(kstpkper=kstpkper)\n",
    "\n",
    "heads[np.isclose(hnoflo, heads)] = np.nan\n",
    "heads[np.isclose(hdry, heads)] = np.nan\n",
    "hin = np.argmax(np.isfinite(heads), axis=0)\n",
    "row, col = np.indices((hin.shape))\n",
    "water_table = heads[hin, row, col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process endpoint information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read endpoint file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review zones and create zone groups for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit parametric distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample endpoints\n",
    "This next cell takes `s` number of stratified random samples from the endpoints. This is in order to make the curve fitting much faster. 50,000 samples seems to work pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate summary statistics\n",
    "\n",
    "Two definitions of young fraction are included. The first is relative to a particle travel time (age) cut-off in years. For steady-state models, it is independent of time and describes the young fraction of the RTD. For transient models, the young fraction depends on the particle release time. The second definition is relative to a calendar date; only particles that recharged after that date are included in the summary statistics. It is equal to the first definition by assuming particle release in 2017. It may be useful for assessing the breakthrough of chemicals released at a known date. For both definitions, the young fraction is described by the number of particles, the mean travel time of those particles, and the fraction of total particles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, 'zone_df.csv')\n",
    "zone_df = pd.read_csv(src, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot CDF and PDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot CDFs for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dst = os.path.join(model_ws, 'RTD')\n",
    "if not os.path.exists(dst):\n",
    "    os.mkdir(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, 'tau.csv')\n",
    "tau_table = pd.read_csv(src, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dst = os.path.join(model_ws, 'fit_dict_{}.pickle'.format(weight_scheme))\n",
    "with open(dst, 'rb') as f:\n",
    "        fit_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for group in fit_dict.keys():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5), sharey=False)\n",
    "\n",
    "    dist = dist_list[0]\n",
    "    uname = 'uni_{}'.format(dist.name)\n",
    "    aname = 'add_{}'.format(dist.name)\n",
    "\n",
    "    part_tt = fit_dict[group]['tt']['rt'] \n",
    "    part_cdf = fit_dict[group]['tt']['rt_cdf']\n",
    "    \n",
    "    if logtransform:\n",
    "        loglabel = 'log'\n",
    "    else:\n",
    "        loglabel = 'linear'\n",
    "    \n",
    "    ax.plot(part_tt, part_cdf, label='Particle', lw=5, color='r', alpha=0.4)\n",
    "\n",
    "    try:\n",
    "        uni_cdf = fit_dict[group]['cdf'][uname]\n",
    "        ax.plot(part_tt, uni_cdf, label='One component', color='k', lw=1)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    fy = -9999\n",
    "    try:\n",
    "        ep_exp = fit_dict[group]['par'][aname]\n",
    "        add_cdf = fit_dict[group]['cdf'][aname]\n",
    "        fy = ep_exp[6]\n",
    "        ax.plot(part_tt, add_cdf, label='Explicitly mixed', color='r', lw=1)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    first = part_tt.min()\n",
    "    try:\n",
    "        tau = tau_table.loc[group, 'tau']\n",
    "        expon = ss.expon(first, tau)\n",
    "        exy = expon.cdf(part_tt)\n",
    "        ax.plot(part_tt, exy, label='Exponential', color='b', lw=1, ls='dashed')\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(first, 100000)\n",
    "    ax.set_ylim(0, 1)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + 0.15, box.width * 1.10, box.height * 0.8])\n",
    "    ax.set_ylabel('Cumulative frequency', fontsize=8)\n",
    "    ax.set_xlabel('Residence time ({}), in years'.format(loglabel), fontsize=8)\n",
    "    ax.legend(loc=0, frameon=False, fontsize=8, handlelength=3, numpoints=1, ncol=2, \n",
    "              bbox_to_anchor=(1.0, -0.2))\n",
    "    ax.set_title('{2:} {3:}\\n{0:} with {1:0.0f}% RTD$_1$'.format(dist.name, fy*100, fpmg.name, group), fontsize=8)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "    dst = 'Cumulative RTD ({}) for all distributions in zone {}--{}.png'.format(loglabel, group, model)\n",
    "    dst_pth = os.path.join(model_ws, 'RTD', dst)\n",
    "    plt.savefig(dst_pth, dpi=300)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PDF for explicit RTD mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of particles at which to compute particle density `numparts`\n",
    "and x axis maxmimum `axmax` for the best looking plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numparts = 1000\n",
    "axmax = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for group in fit_dict.keys():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5), sharey=False)\n",
    "\n",
    "    dist = dist_list[0]\n",
    "    uname = 'uni_{}'.format(dist.name)\n",
    "    aname = 'add_{}'.format(dist.name)\n",
    "\n",
    "    part_cdf = fit_dict[group]['tt']['rt_cdf']\n",
    "    if logtransform:\n",
    "        loglabel = 'log'\n",
    "        part_tt = np.exp(fit_dict[group]['tt']['rt'] )\n",
    "\n",
    "    else:\n",
    "        loglabel = 'linear'\n",
    "        part_tt = fit_dict[group]['tt']['rt'] \n",
    "        \n",
    "    # trim the ages to get a better plot of the pdf\n",
    "    # eliminate ages < 1 year and > 1,000,000 years\n",
    "    lo_trim = part_tt > 1\n",
    "    hi_trim = part_tt < 1.E+06\n",
    "    trim = np.logical_and(lo_trim, hi_trim)\n",
    "    \n",
    "    part_tt = part_tt[trim]\n",
    "    part_cdf = part_cdf[trim]\n",
    "    \n",
    "    x = np.linspace(part_tt.min(), part_tt.max(), numparts)\n",
    "    yi = np.interp(x, part_tt, part_cdf)\n",
    "    pdf = np.diff(yi) / np.diff(x)\n",
    "    xav = (x[0:-1] + x[1:]) / 2\n",
    "    \n",
    "    lx = np.logspace(np.log10(part_tt.min()), np.log10(part_tt.max()), numparts)\n",
    "    lyi = np.interp(lx, part_tt, part_cdf)\n",
    "    pdf = np.diff(lyi) / np.diff(lx)\n",
    "    xav = (lx[0:-1] + lx[1:]) / 2\n",
    "    \n",
    "    ax.plot(xav, pdf, linestyle='None', marker='.', mfc='0.20', mew=0, \n",
    "            label='Particle RTD', ms=5, alpha=0.9)\n",
    "\n",
    "    fy = 0\n",
    "    \n",
    "    try:\n",
    "        ep_exp = fit_dict[group]['par'][aname]\n",
    "        pdf_e_exp = dist(*ep_exp[0:3]).pdf(xav) \n",
    "        ax.plot(xav, pdf_e_exp, color='blue', linestyle='dashed', linewidth=1, label='RTD$_1$')\n",
    "        mean_age_early = dist(*ep_exp[0:3]).mean()\n",
    "        ax.axvline(mean_age_early, 0, 0.1, color='blue', label='RTD$_1$ mean age', lw=2)\n",
    "\n",
    "        ep_exp = fit_dict[group]['par'][aname]\n",
    "        pdf_l_exp = dist(*ep_exp[3:6]).pdf(xav) \n",
    "        ax.plot(xav, pdf_l_exp, color='green', linestyle='dashed', linewidth=1, label='RTD$_2$')\n",
    "        mean_age_late = dist(*ep_exp[3:6]).mean()\n",
    "        ax.axvline(mean_age_late, 0, 0.1, color='green', label='RTD$_2$ mean age', lw=2)\n",
    "\n",
    "        fy = ep_exp[6]\n",
    "        combined_exp = fy * pdf_e_exp + (1 - fy) * pdf_l_exp\n",
    "        ax.fill_betweenx(combined_exp, xav, color='r', linewidth=1, label='Composite RTD', alpha=0.3)\n",
    "        mean_age_mixed = (xav[1:] * combined_exp[1:] * np.diff(xav)).sum()\n",
    "        ax.axvline(mean_age_mixed, 0, 0.1, color='red', label='Composite mean age', lw=2)\n",
    "\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(xav.min(), axmax)\n",
    "    ax.set_ylim(0, )\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + 0.15, box.width * 1.10, box.height * 0.8])\n",
    "    ax.set_ylabel('Density in 1 / years', fontsize=8)\n",
    "    ax.set_xlabel('Residence time ({}), in years'.format(loglabel), fontsize=8)\n",
    "    ax.legend(loc=0, frameon=False, fontsize=8, handlelength=3, numpoints=1, ncol=3, \n",
    "              bbox_to_anchor=(1.1, -0.15))\n",
    "    ax.set_title('{2:} {3:}\\n{0:} with {1:0.0f}% RTD$_1$'.format(dist.name, fy*100, fpmg.name, group), fontsize=8)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "    dst = 'Density of RTD ({}) for all distributions in zone {}--{}.png'.format(loglabel, group, model)\n",
    "    dst_pth = os.path.join(model_ws, 'RTD', dst)\n",
    "    plt.savefig(dst_pth, dpi=300)\n",
    "\n",
    "    # plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
