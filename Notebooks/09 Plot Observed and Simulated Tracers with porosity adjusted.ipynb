{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gp\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2020' \n",
    "\n",
    "num_surf_layers = 3\n",
    "num_depth_groups = 5\n",
    "\n",
    "por = 0.20\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    mod_list.append(mod)\n",
    "                    dir_list.append(dirpath)\n",
    "                    i += 1\n",
    "print('    {} models read'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samp_df = pd.DataFrame()\n",
    "for model_ws in dir_list:\n",
    "    model = os.path.normpath(model_ws).split(os.sep)[2]\n",
    "    src = os.path.join(model_ws, 'sample_dict_wells.csv')\n",
    "    if os.path.exists(src):\n",
    "        data = pd.read_csv(src)\n",
    "        data['model'] = model\n",
    "        samp_df = samp_df.append(data)\n",
    "dst = os.path.join(fig_dir, 'master_sample_fit.csv')\n",
    "samp_df.to_csv(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samp_df.loc[samp_df.Trit < 0.01, 'Trit'] = 0.01\n",
    "samp_df['3H residual'] = (samp_df.Trit - samp_df.calc_3H_) \n",
    "samp_df['3H relative residual'] = (samp_df.Trit - samp_df.calc_3H_) / samp_df.Trit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 8,\n",
    "        'sans-serif' : 'Arial'}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "TritFit_df = pd.Series()\n",
    "df = samp_df.loc[:, ['model', 'por', 'Trit', 'NetworkTyp', 'SuCode', 'calc_3H_']]\n",
    "\n",
    "df_sub = df.copy()\n",
    "\n",
    "mslope, minter, lslope, uslope = ss.theilslopes(y=df_sub['calc_3H_'].values, \n",
    "                                                x=df_sub.Trit.values, alpha=0.95)\n",
    "ktau, kalpha = ss.kendalltau(df_sub.Trit.values, df_sub['calc_3H_'].values, nan_policy='omit')\n",
    "\n",
    "TritFit_df.loc['Theil-Sen slope'] = mslope\n",
    "TritFit_df.loc[\"Kendall's tau\"] = ktau\n",
    "TritFit_df.loc[\"Kendall's tau alpha\"] = kalpha\n",
    "TritFit_df.loc['N'] = df_sub.shape[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.8, 4));\n",
    "ax.plot(df_sub.Trit.values, df_sub['calc_3H_'].values, marker='o', \n",
    "        ls='none', ms=3, alpha=0.3, mec='k', mfc='k');\n",
    "\n",
    "quantiles = 4\n",
    "df_sub.loc[:, 'quant'], bins = pd.qcut(df_sub.Trit, quantiles, retbins=True)\n",
    "xplot = df_sub.loc[:, ['Trit', 'quant']].groupby('quant').agg([min, np.median, max, np.std])\n",
    "yplot = df_sub.loc[:, ['calc_3H_', 'quant']].groupby('quant').agg([min, np.median, max, np.std])\n",
    "xmed_ar = xplot.loc[:, ('Trit', 'median')]\n",
    "ymed_ar = yplot.loc[:, ('calc_3H_', 'median')]\n",
    "ystd_ar = yplot.loc[:, ('calc_3H_', 'std')]\n",
    "\n",
    "yerr = pd.DataFrame()\n",
    "yerr['yhi'] = (yplot.loc[:, ('calc_3H_', 'median')] - yplot.loc[:, ('calc_3H_', 'max')]).abs()\n",
    "yerr['ylo'] = (yplot.loc[:, ('calc_3H_', 'median')] - yplot.loc[:, ('calc_3H_', 'min')]).abs()\n",
    "yerr = yerr.T\n",
    "yerr = yerr[::-1]\n",
    "\n",
    "x = np.arange(25)\n",
    "y = mslope * x + minter\n",
    "ylo = lslope * x + minter\n",
    "yup = uslope * x + minter\n",
    "ax.plot(xmed_ar, ymed_ar, marker='^', ls='none', ms=8, mfc='r', mec='r')\n",
    "ax.plot((0, df_sub.Trit.max()), (0, df_sub.Trit.max()), color='k', linestyle='dashed', alpha=0.50)\n",
    "\n",
    "ax.set_xlabel('Measured tritium concentration');\n",
    "ax.set_ylabel('Calculated tritium concentration');\n",
    "fig.set_tight_layout(True)\n",
    "form_list = ['png', 'pdf', 'tif']\n",
    "for form in form_list:\n",
    "    line = 'Paper #2017WR021531-f7.{}'.format(form)\n",
    "    fig_name = os.path.join(fig_dir, line)\n",
    "    plt.savefig(fig_name, dpi=300)\n",
    "\n",
    "dst = os.path.join(fig_dir, 'trit_fit_df.csv')\n",
    "TritFit_df.to_csv(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TritFit_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
