{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import gdal\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import flopy as fp\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2020' \n",
    "\n",
    "num_surf_layers = 3\n",
    "num_depth_groups = 5\n",
    "\n",
    "por = 0.20\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    mod_list.append(mod)\n",
    "                    dir_list.append(dirpath)\n",
    "                    i += 1\n",
    "print('    {} models read'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and process tracer input file from TracerLPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read input tracers\n",
    "tracer_input_raw = pd.read_excel('../data/tracer input/Copy of TracerLPM_V_1_0B.xlsm', \\\n",
    "                           skiprows=3, sheetname='StoredTracerData', header=0)\n",
    "\n",
    "col_list = ['Tracer', 'CFC-12', 'CFC-11', 'CFC-13', 'SF6', '3H', 'NO3-N']\n",
    "tr_list = ['CFC-12', 'CFC-11', 'CFC-13', 'SF6', '3H', 'NO3-N']\n",
    "tracer_input_df = tracer_input_raw.loc[:, col_list].copy()\n",
    "\n",
    "# delete garbage header rows\n",
    "tracer_input_df = tracer_input_df.iloc[3:, :]\n",
    "\n",
    "# delete blank rows\n",
    "tracer_input_df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# make sure all the tracer data is numeric\n",
    "for col in col_list:\n",
    "    tracer_input_df[col] = pd.to_numeric(tracer_input_df[col])\n",
    "\n",
    "# reverse the date order so that oldest date is first\n",
    "tracer_input_df = tracer_input_df.iloc[::-1]\n",
    "\n",
    "# interpolate decimal years to a regular time series\n",
    "\n",
    "# first change decimal years to equally spaced time series at approximately the same frequency (monthly)\n",
    "# extract the year from the tracer decimal year\n",
    "year = tracer_input_df.Tracer.astype(np.int32())\n",
    "# convert year to a Datetime object\n",
    "dto = pd.to_datetime(year, format='%Y')\n",
    "# is it a leap year?\n",
    "isleap = pd.DatetimeIndex(dto).is_leap_year\n",
    "# find the number of days in the year\n",
    "num_days_in_year = np.where(isleap, 366, 365)\n",
    "# extract the fractional part of the year using modulus division (%)\n",
    "fraction_of_year = tracer_input_df.Tracer % 1\n",
    "# find the number of elapsed days within each year\n",
    "num_days_by_year = fraction_of_year * num_days_in_year\n",
    "# make the number of days a timedelta object\n",
    "td = pd.to_timedelta(num_days_by_year, unit='D')\n",
    "# sum the year (converted to a datetime object) and the timedelta\n",
    "# make the datetime the index\n",
    "tracer_input_df.set_index(dto + td, inplace=True)\n",
    "\n",
    "# create a regular datetime series starting the middle of each month\n",
    "# the frequency approximates the average month within this time span\n",
    "freq = 30.436764\n",
    "freq_str = '{}D'.format(freq)\n",
    "dates = pd.date_range('1850-01-01', '2020-01-01', freq=freq_str) + pd.Timedelta(days=14)\n",
    "\n",
    "# create a union of the original index and the desired index\n",
    "t = tracer_input_df.index.union(dates)\n",
    "\n",
    "# reindex the tracer df using the unioned index\n",
    "tracer_input_df = tracer_input_df.reindex(t)\n",
    "\n",
    "# fill in the gaps corresponding to the new dates using interpolation\n",
    "tracer_input_df = tracer_input_df.interpolate('slinear')\n",
    "\n",
    "# select only the rows with the new dates\n",
    "tracer_input_df = tracer_input_df.loc[dates]\n",
    "\n",
    "# delete blank rows\n",
    "tracer_input_df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# create a spline function based on the last nonzero spl_per months (in this case 60 months)\n",
    "# and use it to extrapolate the tracer concentrations to the end of the time series\n",
    "spl_per = 60\n",
    "\n",
    "for tr in tr_list:\n",
    "    # index of last nonzero tracer value\n",
    "    idx = tracer_input_df.loc[:, tr].nonzero()[0][-1]\n",
    "    # dates of last spl_per monthly nonzero values\n",
    "    x = tracer_input_df.iloc[(idx - spl_per):idx].index.to_julian_date()\n",
    "    # concentrations of last spl_per monthly nonzero values\n",
    "    y = tracer_input_df[tr].iloc[(idx - spl_per):idx]\n",
    "    # create the spline function\n",
    "    spl = UnivariateSpline(x, y)\n",
    "    # dates of the ending zero tracer concentrations\n",
    "    newx = tracer_input_df.iloc[idx:].index.to_julian_date()\n",
    "    # use the spline to fill tracer concentrations to the end\n",
    "    tracer_input_df.loc[idx:, tr] = spl(newx)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tracer(object):\n",
    "    def __init__(self, tracer_input_df, tr):\n",
    "        self.tracer_input_df = tracer_input_df\n",
    "        self.tr = tr\n",
    "        self.tr_size = tracer_input_df.shape[0]\n",
    "        self.input_date = tracer_input_df.index\n",
    "        self.start_date = tracer_input_df.index.min()\n",
    "        self.julian_time = self.input_date.to_julian_date()\n",
    "        self.elapsed_time = self.julian_time - self.julian_time[0]\n",
    "        \n",
    "    def pad_tracer(self, rtd_size):\n",
    "        self.tr_pad = np.zeros((self.tr_size + rtd_size * 2))\n",
    "\n",
    "        self.lbackground = self.tracer_input_df.loc[self.tracer_input_df.index[0], self.tr]\n",
    "        self.rbackground = self.tracer_input_df.loc[self.tracer_input_df.index[-1], self.tr]\n",
    "\n",
    "        self.tr_pad[0 : rtd_size] = self.lbackground\n",
    "        self.tr_pad[rtd_size : (self.tr_size + rtd_size)] = self.tracer_input_df.loc[:, self.tr]\n",
    "        self.tr_pad[(self.tr_size + rtd_size) : ] = self.rbackground\n",
    "        \n",
    "class Sample_gdf(Tracer):\n",
    "    def __init__(self, model_ws):\n",
    "        super().__init__(tracer_input_df, tr)\n",
    "        self.model_ws = model_ws\n",
    "        self.src = os.path.join(self.model_ws, 'WEL', 'sample_gdf.shp')\n",
    "        self.sample_gdf = gp.read_file(self.src)\n",
    "        self.sample_gdf['STAID'] = self.sample_gdf.STAID.astype(np.int64())\n",
    "        self.sample_gdf['DATES'] = pd.to_datetime(self.sample_gdf['DATES'])\n",
    "        self.sample_gdf.index = self.sample_gdf['DATES']\n",
    "        \n",
    "    def extract_well(self, well, sa_in):\n",
    "        self.well = well\n",
    "        self.sa_in = sa_in\n",
    "        self.well_data = self.sample_gdf.loc[self.sample_gdf.STAID == well, ['DATES', 'NetworkTyp', 'SuCode', self.sa_in]]\n",
    "        self.well_data = self.well_data.dropna(axis=0, how='any', inplace=False)\n",
    "        self.well_data['jdate'] = self.well_data.index.to_julian_date()\n",
    "        self.well_data['well'] = well\n",
    "        self.elapsed_sample_time = self.well_data['jdate'] - self.start_date.to_julian_date()\n",
    "        \n",
    "class Resepy(object):\n",
    "    def __init__(self, por, freq):\n",
    "        self.por = por\n",
    "        self.freq = freq\n",
    "        \n",
    "    def get_fit(self, well_dict, method):\n",
    "        # compute the pdf in log space\n",
    "        self.px = np.linspace(0.1, 10, 50000, endpoint=True)\n",
    "        self.pxp = np.exp(self.px) * self.por * 365.25\n",
    "        self.p = well_dict['par'][method]\n",
    "        self.py = self.explicit_pdf(self.px, *self.p)\n",
    "        self.xi = np.arange(0, 1E+04 * self.freq, self.freq)\n",
    "        self.yi = np.interp(self.xi, self.pxp, self.py)        \n",
    "        self.pmf = self.yi / self.yi.sum()\n",
    "        self.rtd_size = self.pmf.shape[0]\n",
    "            \n",
    "    def explicit_pdf(self, t, sh_1, lo_1, sc_1, sh_2, lo_2, sc_2, fy):\n",
    "        _cdf_1 = dist.pdf(t, sh_1, lo_1, sc_1)\n",
    "        _cdf_2 = dist.pdf(t, sh_2, lo_2, sc_2)\n",
    "        return fy * _cdf_1 + (1 - fy) * _cdf_2\n",
    "\n",
    "    def dk(self, thalf):\n",
    "        self.pmfdk = self.pmf * np.exp(-self.xi * np.log(2) / thalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 8,\n",
    "        'sans-serif' : 'Arial'}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "chem_list = [('3H', 'Trit', 'TU', 4499.88)]\n",
    "dist = ss.weibull_min\n",
    "form = 'add'\n",
    "method = '{}_{}'.format(form, dist.name)\n",
    "\n",
    "start = dt.datetime.strptime('1950-01-01', '%Y-%m-%d')\n",
    "end = dt.datetime.strptime('2020-12-31', '%Y-%m-%d')\n",
    "\n",
    "diff_step = 0.01\n",
    "sigma = 3.\n",
    "kwargs = {'ftol':1E-07, 'xtol':1E-07, 'max_nfev':200, 'loss':'soft_l1', 'diff_step':diff_step}\n",
    "# kwargs = {'ftol':1E-07, 'xtol':1E-07, 'max_nfev':200, 'loss':'huber', 'diff_step':diff_step}\n",
    "\n",
    "for model_ws in dir_list:\n",
    "    sample_fit = pd.DataFrame()\n",
    "    model = os.path.normpath(model_ws).split(os.sep)[2]\n",
    "    nam_file = '{}.nam'.format(model)\n",
    "    new_ws = os.path.join(model_ws, 'WEL')\n",
    "    geo_ws = os.path.dirname(model_ws)\n",
    "\n",
    "    print(\"working model is {}\".format(model_ws))\n",
    "    try:\n",
    "        src = os.path.join(model_ws, 'fit_dict_wells_{}.pickle'.format(model))\n",
    "        with open(src, 'rb') as f:\n",
    "            fit_dict = pickle.load(f)\n",
    "\n",
    "        s = Sample_gdf(model_ws)\n",
    "        tr_in, sa_in, unit, dkr8 = chem_list[0]\n",
    "        t = Tracer(tracer_input_df, tr_in)\n",
    "\n",
    "        for well, d in fit_dict.items():\n",
    "            s.extract_well(well, sa_in)\n",
    "            if s.well_data.shape[0] > 0:\n",
    "                fig, ax = plt.subplots(1, 1)\n",
    "                def simeq(xi, por):\n",
    "                    r = Resepy(por, freq)\n",
    "                    r.get_fit(d, method)\n",
    "                    r.dk(dkr8)\n",
    "                    t.pad_tracer(r.rtd_size)\n",
    "                    btc = np.convolve(r.pmfdk, t.tr_pad, mode='valid')\n",
    "                    return np.interp(s.elapsed_sample_time, t.elapsed_time, btc[:t.tr_size])  \n",
    "\n",
    "                bnds = (0.01, 0.40)\n",
    "                porhat, cov = so.curve_fit(simeq, s.well_data['DATES'], s.well_data[sa_in], \n",
    "                                           bounds = bnds, method='trf', sigma=sigma, **kwargs)#or 'dogbox') \n",
    "\n",
    "                r = Resepy(porhat, freq)\n",
    "                r.get_fit(d, method)\n",
    "                r.dk(dkr8)\n",
    "                t.pad_tracer(r.rtd_size)\n",
    "                btc = np.convolve(r.pmfdk, t.tr_pad, mode='valid')\n",
    "                yhat = np.interp(s.elapsed_sample_time, t.elapsed_time, btc[:t.tr_size])\n",
    "\n",
    "                if np.isfinite(cov).all():\n",
    "                    s.well_data['cov'] = np.diag(cov)[0]\n",
    "                else:\n",
    "                    dpor = porhat * (1 + diff_step)\n",
    "                    neweq = simeq(s.well_data['DATES'], dpor)\n",
    "                    X =  (yhat - neweq) / (diff_step * porhat)\n",
    "                    scov = sigma / (X.T.dot(X))\n",
    "                    s.well_data['cov'] = scov\n",
    "\n",
    "                colu = 'calc_{}_'.format(tr_in)\n",
    "                s.well_data[colu] = yhat\n",
    "                s.well_data['por'] = r.por[0]\n",
    "\n",
    "                sample_fit = sample_fit.append(s.well_data)    \n",
    "                line = '{} {:0.3f}'.format(s.well, porhat[0])\n",
    "\n",
    "                ax.plot(t.tracer_input_df.index, btc[:t.tr_size], color='k', label='_nolegend_', linestyle='solid');\n",
    "                ax.plot(s.well_data['DATES'], yhat, linestyle='None', marker='x', color='k', label=line, ms=8);\n",
    "                ax.plot(s.well_data['DATES'], s.well_data[sa_in], linestyle='None', marker='o', label='_nolegend_', color='k');\n",
    "\n",
    "                ax.set_xlim(start, end)\n",
    "                ax.set_ylim(0.1, 10000)\n",
    "                ax.set_ylabel('{} in {}'.format('Tritium concentration', 'tritium units'))\n",
    "                ax.set_yscale('log')\n",
    "                ax.legend()\n",
    "\n",
    "                fig.set_tight_layout(True)\n",
    "\n",
    "                dst = '{} distribution for well {}.png'.format(tr_in, well)\n",
    "                dst_pth = os.path.join(model_ws, dst)\n",
    "                plt.savefig(dst_pth, dpi=600)\n",
    "                plt.close()\n",
    "        dst = os.path.join(model_ws, 'sample_dict_wells.csv')\n",
    "        sample_fit.to_csv(dst)\n",
    "\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        print('no node or sample files for {}'.format(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
