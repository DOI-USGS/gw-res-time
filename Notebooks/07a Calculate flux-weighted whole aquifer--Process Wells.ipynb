{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Create a general MODFLOW model from the NHDPlus dataset--calculate age distributions and tracer concentrations at pumping wells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'   \n",
    "%matplotlib notebook\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "import os\n",
    "import shutil\n",
    "import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import flopy as fp\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "ft2m = 0.3048006096012192\n",
    "add_bedrock = True\n",
    "well_pth = '../Data/Wells/all_glac_wells.shp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read all_glac_wells shapefile of points from ChemTool\n",
    "well_shp = gp.read_file(well_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell doesn't do anything in this notebook, but it can used as a template for creating a batch python script. The rest of the notebook should placed in the try/except statement (with the except moved to the end of the script). This loops through the default and the calibration directories for the scenario selected in gen_mod_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2020' \n",
    "\n",
    "num_surf_layers = 3\n",
    "num_depth_groups = 5\n",
    "\n",
    "por = 0.20\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    mod_list.append(mod)\n",
    "                    dir_list.append(dirpath)\n",
    "                    i += 1\n",
    "print('    {} models read'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read existing general model MODFLOW packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_ws in dir_list:\n",
    "    model = os.path.normpath(model_ws).split(os.sep)[2]\n",
    "    nam_file = '{}.nam'.format(model)\n",
    "    new_ws = os.path.join(model_ws, 'WEL')\n",
    "    geo_ws = os.path.dirname(model_ws)\n",
    "\n",
    "    print(\"working model is {}\".format(model_ws))\n",
    "    print ('Reading model information')\n",
    "\n",
    "    fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                                   load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "    dis = fpmg.get_package('DIS')\n",
    "    bas = fpmg.get_package('BAS6')\n",
    "    upw = fpmg.get_package('UPW')\n",
    "    oc = fpmg.get_package('OC')\n",
    "\n",
    "    delr = dis.delr\n",
    "    delc = dis.delc\n",
    "    nlay = dis.nlay\n",
    "    nrow = dis.nrow\n",
    "    ncol = dis.ncol\n",
    "    bot = dis.getbotm()\n",
    "#     top = dis.gettop()\n",
    "    # hk = upw.hk.get_value()\n",
    "\n",
    "    hnoflo = bas.hnoflo\n",
    "    ibound = np.asarray(bas.ibound.get_value())\n",
    "    hdry = upw.hdry\n",
    "\n",
    "    print ('   ... done') \n",
    "\n",
    "    # FloPy loads MODFLOW packages but not their name-file unit numbers, so these have to be read separately.\n",
    "\n",
    "    src = os.path.join(model_ws, fpmg.namefile)\n",
    "    name_file_df = pd.read_table(src, header=None, comment='#', delim_whitespace=True, \n",
    "                  names=['package', 'unit', 'filename', 'type'])\n",
    "\n",
    "    name_file_df['package'] = name_file_df.package.str.lower()\n",
    "    name_file_df['ext'] = name_file_df.filename.str.split('.').str.get(1)\n",
    "    name_file_df.set_index('package', inplace=True)\n",
    "\n",
    "    # Compute the top of the saturated zone by taking the minimum of the aquifer top elevation and the simulated head in the top layer. Concatenate the saturated top onto the bottom elevations resulting in a 3D grid of vertical cell boundary elevations. Take the difference between layers to get a 3D grid of layer thicknesses. NaNs are propagated through the minimum function so that dry cells are not used to compute thickness. Once the thickness is computed the NaNs are converted back to 0 because a cell with a NaN has no saturation. Save open raster_src for use later.\n",
    "\n",
    "    src = os.path.join(model_ws, fpmg.namefile)\n",
    "    name_file_df = pd.read_table(src, header=None, comment='#', delim_whitespace=True, \n",
    "                  names=['package', 'unit', 'filename', 'type'])\n",
    "\n",
    "    name_file_df['package'] = name_file_df.package.str.lower()\n",
    "    name_file_df['ext'] = name_file_df.filename.str.split('.').str.get(1)\n",
    "    name_file_df.set_index('package', inplace=True)\n",
    "\n",
    "    disnum = name_file_df.loc['dis', 'unit']\n",
    "    disnam = name_file_df.loc['dis', 'filename']\n",
    "\n",
    "    if 'mnw2' not in name_file_df.index:\n",
    "        new_ws = os.path.abspath(os.path.join(model_ws, 'WEL'))\n",
    "        if not os.path.exists(new_ws):\n",
    "            os.makedirs(new_ws)\n",
    "    else:\n",
    "        new_ws = model_ws\n",
    "\n",
    "    head_file_name = '{}.hds'.format(model)\n",
    "    src = os.path.join(model_ws, head_file_name)\n",
    "    hd_obj = fp.utils.HeadFile(src)\n",
    "    heads = hd_obj.get_data((0, 0))\n",
    "    heads[heads == hnoflo] = np.nan\n",
    "    heads[heads <= hdry] = np.nan\n",
    "    hin = np.argmax(np.isfinite(heads), axis=0)\n",
    "    row, col = np.indices((hin.shape))\n",
    "    water_table = heads[hin, row, col]\n",
    "\n",
    "    water_table[ibound[0,:,:] == 0] = np.nan\n",
    "    \n",
    "    src = os.path.join(geo_ws, 'top.tif')\n",
    "    ph = gdal.Open(src)\n",
    "\n",
    "    band = ph.GetRasterBand(1)\n",
    "    top = band.ReadAsArray()\n",
    "    gt = ph.GetGeoTransform()\n",
    "\n",
    "    ph = None\n",
    "    band = None   \n",
    "\n",
    "    grid = np.zeros((nlay + 1, nrow, ncol))\n",
    "    grid[0, :, :] = top\n",
    "    grid[1:, :, :] = dis.getbotm()\n",
    "\n",
    "#     Read shapefile created from chemtool pull (done in a separate notebook). Clip it to the general model watershed shapefile. Extract spatial coordinates and save it to the new working directory as sample_gdf.shp.\n",
    "\n",
    "    print ('   Reading sample data')\n",
    "\n",
    "    # read the watershed and well shapefiles\n",
    "    domain_file = os.path.join(geo_ws, 'domain_outline.shp')\n",
    "    domain_diss = gp.read_file(domain_file)\n",
    "\n",
    "    # intersect the watershed (domain_diss) and well shapefiles\n",
    "    # and find the rows where the intersection is not null\n",
    "    mp = domain_diss.geometry[0]\n",
    "    in_area_index = ~well_shp['geometry'].intersection(mp).isnull()\n",
    "\n",
    "    # create a geodataframe (sample_gdf) with all the well attributes\n",
    "    sample_gdf = well_shp.loc[in_area_index].copy()\n",
    "\n",
    "    # extract the sample point coordinates\n",
    "    sample_gdf['xg'] = sample_gdf.geometry.apply(lambda p : p.x)\n",
    "    sample_gdf['yg'] = sample_gdf.geometry.apply(lambda p : p.y)\n",
    "\n",
    "    # save\n",
    "    if sample_gdf.shape[0] > 0:\n",
    "        sample_gdf.to_file(os.path.join(new_ws, 'sample_gdf.shp'))\n",
    "\n",
    "    print ('   ... done')\n",
    "\n",
    "#     Next cell is for batch mode.\n",
    "\n",
    "    try:\n",
    "\n",
    "    #     Apply an affine transform using linear algebra. The transformation matrix is created from the geotransform data in one of the geotiff files created in NB1.\n",
    "\n",
    "        print ('   Creating well data frame')\n",
    "\n",
    "        # eliminate duplicate wells that have more than one sample\n",
    "        ob_well_unq, ob_well_unq_ind = np.unique(sample_gdf.STAID.values, return_index=True)\n",
    "        cl = ['ALT_VA', 'DEC_LAT_VA', 'DEC_LONG_V', 'HOLE_DEPTH', 'MAXOFOPEN_', 'MINOFOPEN_', \n",
    "              'NetworkTyp', 'STAID', 'SuCode', 'WELL_DEPTH', 'xg', 'yg', 'geometry']\n",
    "        well_gdf = sample_gdf.iloc[ob_well_unq_ind, :].copy()\n",
    "        well_gdf = well_gdf.loc[:, cl]\n",
    "        \n",
    "        # read geotransform list from a geotiff\n",
    "        src_filename = os.path.join(os.path.dirname(model_ws), 'top.tif')\n",
    "        data_source = gdal.Open(src_filename)\n",
    "        ncol, nrow = data_source.RasterXSize, data_source.RasterYSize\n",
    "        gt = data_source.GetGeoTransform()\n",
    "        data_source = None\n",
    "\n",
    "        # format the geotransformation list into an affine transformation matrix\n",
    "        forward_transform = np.array(gt).reshape(2, -1)\n",
    "        # add a row to get homogeneous coodinates (offsets are in the first column)\n",
    "        forward_transform = np.vstack((forward_transform, [1, 0, 0]))\n",
    "        # invert the forward transform\n",
    "        reverse_transform = np.linalg.inv(forward_transform)\n",
    "\n",
    "        # reverse transform the real-world coordinate to pixel coordinates (row, column)\n",
    "        well_gdf['one'] = 1\n",
    "        wpts = well_gdf[['xg', 'yg', 'one']]\n",
    "        wpp = reverse_transform.dot(wpts.T)\n",
    "        well_gdf['xm'] = wpp[1, :]\n",
    "        well_gdf['ym'] = wpp[2, :]\n",
    "\n",
    "        # row and column (and layer) are zero based\n",
    "        well_gdf['col'] = np.int32(well_gdf.xm)\n",
    "        well_gdf['row'] = np.int32(well_gdf.ym)\n",
    "\n",
    "        # add local coordinates of well within cell\n",
    "        well_gdf['welx'] = well_gdf.xm - well_gdf.col\n",
    "        well_gdf['wely'] = 1 - (well_gdf.ym - well_gdf.row)\n",
    "\n",
    "        # a little db checking:\n",
    "        # elim rows with no altitude\n",
    "        # elimn rows where screen top and bot are reversed\n",
    "        well_gdf = well_gdf.loc[well_gdf.ALT_VA.notnull(), :]\n",
    "        # well_gdf = well_gdf.loc[well_gdf.MAXOFOPEN_ > well_gdf.MINOFOPEN_, :]\n",
    "\n",
    "        # convert to meters and to float \n",
    "        well_gdf['ALT_VA'] =  well_gdf['ALT_VA'].astype(np.float32()) * ft2m\n",
    "        well_gdf['MAXOFOPEN_'] = well_gdf['MAXOFOPEN_'].astype(np.float32()) * ft2m\n",
    "        well_gdf['MINOFOPEN_'] = well_gdf['MINOFOPEN_'].astype(np.float32()) * ft2m\n",
    "        well_gdf['WELL_DEPTH'] = well_gdf['WELL_DEPTH'].astype(np.float32()) * ft2m\n",
    "        well_gdf['HOLE_DEPTH'] = well_gdf['HOLE_DEPTH'].astype(np.float32()) * ft2m\n",
    "\n",
    "        _r, _c = well_gdf['row'].values, well_gdf['col'].values\n",
    "\n",
    "        # get bedrock altitude\n",
    "        if add_bedrock:\n",
    "            well_gdf['bedrock'] = grid[dis.nlay - 1, _r, _c]\n",
    "        else:\n",
    "            well_gdf['bedrock'] = grid[dis.nlay, _r, _c]   \n",
    "\n",
    "        # get bedrock depth\n",
    "        well_gdf['bedrock_depth'] = grid[0, _r, _c] - well_gdf['bedrock']\n",
    "\n",
    "        # estimate depth to screen bottom as, in order\n",
    "        # stated depth, well depth, hole depth, bedrock depth \n",
    "        well_gdf['alt_depth'] = np.where(well_gdf.MAXOFOPEN_.notnull(), well_gdf.MAXOFOPEN_, well_gdf.WELL_DEPTH)\n",
    "        well_gdf['alt_depth'] = np.where(well_gdf.alt_depth.notnull(), well_gdf.alt_depth, well_gdf.HOLE_DEPTH)\n",
    "        well_gdf['alt_depth'] = np.where(well_gdf.alt_depth.notnull(), well_gdf.alt_depth, well_gdf.bedrock_depth)\n",
    "\n",
    "        # get estimated altitude of screen bottom\n",
    "        well_gdf['bot'] = well_gdf.ALT_VA - well_gdf.alt_depth\n",
    "        # set screen bottom to maximum of bedrock or estimated screen bottom\n",
    "        well_gdf['screenbot'] = well_gdf.loc[:, ['bot', 'bedrock']].max(axis=1)\n",
    "\n",
    "        # calculate screen length; set to 5 meters if it is missing\n",
    "        well_gdf['screenlen'] = well_gdf.MAXOFOPEN_ - well_gdf.MINOFOPEN_\n",
    "        well_gdf['screenlen'].fillna(5, inplace=True)\n",
    "\n",
    "        # get the water table altitude\n",
    "        well_gdf['watertable'] = water_table[well_gdf.row, well_gdf.col]\n",
    "        # elim wells if the water table is below the screen bottom\n",
    "        well_gdf = well_gdf.loc[well_gdf.watertable > well_gdf.screenbot]\n",
    "\n",
    "        # estimate the screen top, keeping the screen length accurate\n",
    "        well_gdf['top'] = well_gdf.screenbot + well_gdf.screenlen\n",
    "        # set screen top to minimum of water table or estimated screen top\n",
    "        well_gdf['screentop'] = well_gdf.loc[:, ['watertable', 'top']].min(axis=1)\n",
    "        \n",
    "        num_wells = well_gdf.shape[0]\n",
    "        well_gdf.to_file(os.path.join(new_ws, 'well_gdf.shp'))\n",
    "        \n",
    "        # get layer boundary elevations for well cells (num layers + 1 incl top)\n",
    "        # this information is needed for the well diagrams plotted below\n",
    "        # however, shapefiles will not accept an array in a field, therefore\n",
    "        # this operation has to be done after saving the shapefile\n",
    "        # the layer elevation data are saved in node_df\n",
    "        lays = grid[:, well_gdf.row.values, well_gdf.col.values]\n",
    "        well_gdf['layer_el'] = tuple(lays.T)\n",
    "\n",
    "    #     Read file of actual average pumping rates for NAWQA PAS wells from \"PumpingRate.txt\". Location of that file is specified in model_spec.py. If there is no pumping rate, use the default (pas_q could be 0).\n",
    "\n",
    "        print ('   Creating nodes')\n",
    "\n",
    "        # decide if each layer has part of the well screen in it\n",
    "        # --the well screen bottom has to be below the top of the layer (tmp1)\n",
    "        # AND the well screen top has to be above the bottom of the layer (tmp2)\n",
    "        tmp1 = lays[:-1].T > well_gdf.screenbot.values.reshape(-1, 1)\n",
    "        tmp2 = lays[1:].T < well_gdf.screentop.values.reshape(-1, 1)\n",
    "        # islayer is a boolean array (num_nodes, nlay); \n",
    "        # True, if well screen is present in that layer;\n",
    "        # can be used to pull well cell layer boundaries\n",
    "        islayer = np.logical_and(tmp1, tmp2)\n",
    "        num_nodes = islayer.sum()\n",
    "        # make groupnum, which is an integer index to go from well_gdf to node_df\n",
    "        # a, b = np.mgrid[0:num_nodes, 0:dis.nlay]\n",
    "        a, b = np.indices((islayer.shape))\n",
    "        groupnum = a[islayer]\n",
    "\n",
    "        node_df = pd.DataFrame(index = np.arange(num_nodes))\n",
    "        node_df['lay'] = b[islayer].astype(np.int32)\n",
    "        node_df['row'] = well_gdf.iloc[groupnum, :].row.values\n",
    "        node_df['col'] = well_gdf.iloc[groupnum, :].col.values\n",
    "        node_df['screentop'] = well_gdf.iloc[groupnum, :].screentop.values\n",
    "        node_df['screenbot'] = well_gdf.iloc[groupnum, :].screenbot.values\n",
    "        node_df['screen_length'] = node_df.screentop - node_df.screenbot\n",
    "        node_df['cell_top_elev'] = lays[0:-1].T[islayer]\n",
    "        node_df['cell_bot_elev'] = lays[1:].T[islayer]\n",
    "        node_df['wel_x'] = well_gdf.iloc[groupnum, :].welx.values\n",
    "        node_df['wel_y'] = well_gdf.iloc[groupnum, :].wely.values\n",
    "        node_df['cellx'] = dis.delr[node_df.col]\n",
    "        node_df['celly'] = dis.delc[node_df.row]\n",
    "        node_df['cellz'] = node_df.cell_top_elev - node_df.cell_bot_elev\n",
    "        node_df['wel_z_top'] = np.minimum(node_df.cellz, node_df.screentop - node_df.cell_bot_elev)\n",
    "        node_df['wel_z_bot'] = np.maximum(0, node_df.screenbot - node_df.cell_bot_elev)\n",
    "        node_df['screen_length_in_cell'] = node_df.wel_z_top - node_df.wel_z_bot\n",
    "        node_df['scrn_frac'] = node_df.screen_length_in_cell / node_df.screen_length\n",
    "        # node_df['pumping_rate'] = well_gdf.iloc[groupnum, :].PumpRate.values * node_df['scrn_frac']\n",
    "        node_df['layer_el'] = well_gdf.iloc[groupnum, :].layer_el.values\n",
    "\n",
    "        # Add sequence, group numbers, and station id (staid)\n",
    "        def t_func(x):\n",
    "            return x.lay * nrow * ncol + x.row * ncol + x.col\n",
    "        node_df['seqnum'] = node_df.apply(t_func, axis = 1).astype(np.int32)\n",
    "\n",
    "        node_df['group'] = groupnum\n",
    "        node_df['group'] = np.arange(node_df.shape[0])\n",
    "\n",
    "        node_df['staid'] = well_gdf.STAID.values[groupnum]\n",
    "        node_df['node_id'] = node_df.staid.astype(str) + '_' + node_df.lay.astype(str)\n",
    "        node_df.set_index('node_id', inplace=True)\n",
    "\n",
    "        # save\n",
    "        node_df.to_csv(os.path.join(new_ws, 'node_df.csv'))\n",
    "\n",
    "        print ('   ... done')\n",
    "        \n",
    "\n",
    "        for i, well in well_gdf.iterrows():\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(2,5), sharey=True)\n",
    "\n",
    "            row, col = well.row, well.col\n",
    "            wt = well.watertable\n",
    "            wtop = well.top\n",
    "            lays = well.layer_el\n",
    "            stop = well.screentop\n",
    "            sbot = well.screenbot\n",
    "            K = np.array(upw.hk.get_value())[:, row, col]\n",
    "\n",
    "            colors = ['b', 'g', 'r']\n",
    "\n",
    "            ax.axhline(wt, c='b')\n",
    "            ax.axhline(wtop, c='g', lw=2)\n",
    "            for lay in range(num_surf_layers):\n",
    "                ax.axhspan(lays[lay], lays[lay + 1], color=colors[lay], alpha=0.2)\n",
    "                ax.annotate('Layer {}'.format(lay + 1),\n",
    "                    xy=(0.5, (lays[lay] + lays[lay + 1]) / 2), #fontweight='bold',\n",
    "                    size=8, ha='center', va='bottom')\n",
    "                ax.annotate('{:3.2f} m/d'.format(K[lay]),\n",
    "                    xy=(0.5, (lays[lay] + lays[lay + 1]) / 2), #fontweight='bold',\n",
    "                    size=8, ha='center', va='top')\n",
    "\n",
    "            ax.set_title('{}\\n{}:{}'.format(well.STAID, well.NetworkTyp, well.SuCode), {'fontsize': 8})\n",
    "            ax.annotate('Water table',\n",
    "                        xy=(0.50, wt), \n",
    "                        size=8, ha='center', va='top')\n",
    "\n",
    "            ax.annotate('Land surface',\n",
    "                        xy=(0.50, wtop), \n",
    "                        size=8, ha='center', va='bottom')\n",
    "\n",
    "            tnode = node_df.loc[node_df.staid == well.STAID, :]\n",
    "            stop = tnode.screentop.max()\n",
    "            sbot = tnode.screenbot.min()\n",
    "\n",
    "            # Create a Rectangle patch for the well screen\n",
    "            rect = patches.Rectangle((0, sbot), 1.0, stop-sbot, linewidth=1, \n",
    "                                     edgecolor='k', facecolor='k', alpha=0.2, hatch='/')\n",
    "\n",
    "            # Add the patch to the Axes\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            ax.set_ylabel('Altitude in meters', fontsize=8)\n",
    "            ax.tick_params(\n",
    "            axis='x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom='off',      # ticks along the bottom edge are off\n",
    "            top='off',         # ticks along the top edge are off\n",
    "            labelbottom='off') # labels along the bottom edge are off\n",
    "\n",
    "            ax.tick_params(\n",
    "            axis='y',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            labelsize=8)\n",
    "\n",
    "            fig.set_tight_layout(True)\n",
    "            dst = os.path.join(model_ws, 'well_diagrams')\n",
    "            if not os.path.exists(dst):\n",
    "                print ('Making directory {}'.format(dst))\n",
    "                os.mkdir(dst)\n",
    "\n",
    "            form_list = ['png', 'pdf', 'tif']\n",
    "            for form in form_list:\n",
    "                fig_name = os.path.join(dst, '{}.{}'.format(well.STAID, form))\n",
    "                plt.savefig(fig_name)\n",
    "            plt.close()\n",
    "    except ValueError:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
