{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import shelve\n",
    "import pickle\n",
    "from scipy.optimize import OptimizeWarning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mt\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import datetime as dt\n",
    "import gdal, osr\n",
    "gdal.UseExceptions()\n",
    "import flopy as fp\n",
    "\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so\n",
    "from scipy import interpolate as si\n",
    "from sklearn import linear_model\n",
    "\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.model_selection import learning_curve, validation_curve, ShuffleSplit, cross_val_score, cross_val_predict, KFold \n",
    "from sklearn.metrics import explained_variance_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2020' \n",
    "\n",
    "num_surf_layers = 3\n",
    "num_depth_groups = 5\n",
    "\n",
    "por = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_list = []\n",
    "pfile = 'fit_dict_res_all_layers.pickle'\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if f == pfile:\n",
    "                    pth = os.path.join(dirpath, f)\n",
    "                    model = os.path.normpath(pth).split(os.sep)[2]\n",
    "                    dir_list.append(pth)\n",
    "                    mto = os.path.getmtime(pth)\n",
    "                    d = dt.datetime.fromtimestamp(mto)\n",
    "                    mt = dt.datetime.strftime(d, '%b. %d, %Y at %I:%M %p')\n",
    "                    print('{:50s} {}'.format(model, mt))\n",
    "print('\\n    {} models read'.format(len(dir_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shp = gp.read_file('../Data/Watersheds/watersheds.shp')\n",
    "\n",
    "shp['model_num'] = shp.model_num.astype(np.int32())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arr = np.zeros((len(dir_list), 12))\n",
    "\n",
    "mod_list = list()\n",
    "dist = ss.weibull_min\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 8,\n",
    "        'sans-serif' : 'Arial'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig, axs = plt.subplots(5, 6, sharex=True, sharey=True, figsize=(7.4, 8), \n",
    "                    gridspec_kw={'wspace':0.05, 'hspace':0.05})\n",
    "axs = axs.ravel()\n",
    "\n",
    "uname = 'uni_{}'.format(dist.name)\n",
    "aname = 'add_{}'.format(dist.name)\n",
    "iname = 'imp_{}'.format(dist.name)\n",
    "\n",
    "diff_step = 0.0001\n",
    "sigma = 1.\n",
    "kwargs = {'ftol':1E-07, 'xtol':1E-07, 'max_nfev':5000, 'loss':'soft_l1', 'diff_step':diff_step, 'f_scale':1.0}\n",
    "\n",
    "for i, j in shp.iterrows():\n",
    "    model = j.model_name\n",
    "    pth = [item for item in dir_list if model in item][0]\n",
    "    plot = j.model_num - 1\n",
    "    \n",
    "    mod_list.append(model)\n",
    "    model_ws = os.path.dirname(pth)\n",
    "    \n",
    "    # read the dictionary with fitted parameters and particle travel times \n",
    "    with open(pth, 'rb') as f:\n",
    "        pick = pickle.load(f)\n",
    "    x = pick[model]['tt']['rt']\n",
    "    y = pick[model]['tt']['rt_cdf']\n",
    "    uni_cdf = pick[model]['cdf'][uname]\n",
    "    add_cdf = pick[model]['cdf'][aname]\n",
    "\n",
    "    # read the text file with mean age information (tau)\n",
    "    src = os.path.join(model_ws, 'tau.txt')\n",
    "    with open(src) as f:\n",
    "        lines = f.readlines()\n",
    "    items = [item.split()[6] for item in lines]\n",
    "    tau_glacial = np.float(items [0])\n",
    "    tau_bedrock = np.float(items [1])\n",
    "    tau_total = np.float(items [2])\n",
    "    items = [item.split()[4] for item in lines]\n",
    "    frac = np.float(items[4])\n",
    "\n",
    "    # compute the exponential distribution using the calculated mean age (tau)\n",
    "    expon = ss.expon(np.exp(x.min()), tau_glacial)\n",
    "    exy = expon.cdf(np.exp(x))\n",
    "    \n",
    "    # start plotting stuff ...\n",
    "    ax = axs[plot]\n",
    "    # ... the calculated exponential distribution CDF\n",
    "    ax.semilogx(np.exp(x) / por, exy, label='Calculated', color='k', lw=1, ls='dotted')\n",
    "\n",
    "    # ... the CDFs from particle and parametric distributions\n",
    "    try:\n",
    "        ax.semilogx(np.exp(x), y, label='Particle', lw=5, color='r', alpha=0.4)\n",
    "        ax.semilogx(np.exp(x), uni_cdf, label='Univariate', color='k', lw=1.5, ls='solid')\n",
    "        ax.semilogx(np.exp(x), add_cdf, label='Explicitly mixed', color='b', lw=1, ls='dashed')\n",
    "        ax.set_xlim(1, 10000)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    subtitle = '{}'.format(plot + 1, fontsize=8)\n",
    "    ax.text(2, 0.85, subtitle, fontsize=8)\n",
    "\n",
    "    # calculate error measures by interpolating the particle travel times and \n",
    "    # calculated exponential distribution to the same x coordinates\n",
    "    newx = np.logspace(np.log10(np.exp(x)).min(), np.log10(np.exp(x)).max(), 1000)\n",
    "    newy1 = np.interp(newx, np.exp(x) / por, exy)\n",
    "    newy2 = np.interp(newx, np.exp(x), uni_cdf)\n",
    "    \n",
    "    resid = newy1 - newy2\n",
    "    err = (resid).T.dot(resid)\n",
    "    rmse = np.sqrt(err / newx.shape[0])\n",
    "\n",
    "    pars = pick[model]['par'][uname]\n",
    "    arr[plot, 0] = plot + 1\n",
    "    arr[plot, 1:4] = pars\n",
    "    arr[plot, 4] = rmse\n",
    "    arr[plot, 5] = frac\n",
    "    arr[plot, 6] = tau_glacial\n",
    "    arr[plot, 7] = tau_bedrock\n",
    "    arr[plot, 8] = tau_total\n",
    "    \n",
    "    def efunc(x, scale):\n",
    "        return 1 - np.exp(-scale * x)\n",
    "    def wfunc(x, shape, scale):\n",
    "        return 1 - np.exp(-(x / scale) ** shape)\n",
    "\n",
    "    bnds = (0.000001, 0.2)  \n",
    "    pe_opt, pe_cov = so.curve_fit(efunc, newx, newy1, \n",
    "                                   bounds = bnds, method='dogbox', sigma=sigma, **kwargs)\n",
    "    bnds = ((0.00001, 0.00001), (1000, 3000))    \n",
    "    pw_opt, pw_cov = so.curve_fit(wfunc, newx, newy2, \n",
    "                                   bounds = bnds, method='trf', sigma=sigma, **kwargs)\n",
    "    \n",
    "    arr[plot, 9] = pe_opt\n",
    "    arr[plot, 10:] = pw_opt    \n",
    "\n",
    "ax.legend(bbox_to_anchor=[0.45, -0.4], ncol=4, frameon=False)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "fig.text(0.05, 0.55, 'Cumulative frequency', rotation=90)\n",
    "fig.text(0.4, 0.05, 'Residence time / porosity in years')\n",
    "form_list = ['png', 'pdf', 'tif']\n",
    "for form in form_list:\n",
    "    line = 'Paper #2017WR021531-f05.{}'.format(form)\n",
    "    fig_name = os.path.join(fig_dir, line)\n",
    "    plt.savefig(fig_name, dpi=600)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['model_num', 'shape', 'location', 'scale', 'rmse', 'frac', 'tau_glacial', \n",
    "        'tau_bedrock', 'tau_total', 'exp_scale', 'wei_shape', 'wei_scale']\n",
    "df = pd.DataFrame(arr, columns=cols, index=mod_list)\n",
    "df['model_num'] = df.model_num.astype(np.int32).astype('str')\n",
    "df.loc[:, 'inv_exp_scale'] = 1 / df['exp_scale']\n",
    "df.loc[:, 'tau_div_por'] = df['tau_glacial'] / por\n",
    "dffile_name = os.path.join(fig_dir, 'weib_and_exp_fit.csv')\n",
    "df.to_csv(dffile_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
