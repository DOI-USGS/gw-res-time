{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to get residence-time distribution (RTD) for the entire aquifer from an existing MODFLOW model. It is possible to read in any group or label from a 3D array and make RTDs for those groups. The approach is to \n",
    "* read an existing model\n",
    "* create flux-weighted particle starting locations in every cell\n",
    "* run MODPATH and read endpoints\n",
    "* fit parametric distributions\n",
    "\n",
    "This notebook fits parametric distributions. Another notebook creates flux-weighted particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mt\n",
    "import flopy as fp\n",
    "import imeth\n",
    "import fit_parametric_distributions\n",
    "import pandas as pd\n",
    "import gdal\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.interpolate import griddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set user-defined variables\n",
    "\n",
    "MODFLOW and MODPATH use elapsed time and are not aware of calendar time. To place MODFLOW/MODPATH elapsed time on the calendar, two calendar dates were specified at the top of the notebook: the beginning of the first stress period (`mf_start_date`) and when particles are to be released (`mp_release_date`). The latter date could be used in many ways, for example to represent a sampling date, or it could be looped over to create a time-lapse set of ages. \n",
    "\n",
    "`num_surf_layers` is an arbitrary layer number on which to divide the model domain for calculating RTDs. For example, in glacial aquifers it could represent the layer number of the bottom of unconsolidated deposits. In that case, anything below this layer could be considered bedrock.\n",
    "\n",
    "`num_depth_groups` is an arbitrary number of equally groups starting from the water table to the bottom of the lowest model layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through home directory to get list of name files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2020' \n",
    "\n",
    "num_surf_layers = 3\n",
    "num_depth_groups = 5\n",
    "\n",
    "por = 0.20\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    mod_list.append(mod)\n",
    "                    dir_list.append(dirpath)\n",
    "                    i += 1\n",
    "print('    {} models read'.format(i))\n",
    "\n",
    "model_area = Dropdown(\n",
    "    options=mod_list,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = model_area.value\n",
    "model_ws = [item for item in dir_list if model in item][0]\n",
    "nam_file = '{}.nam'.format(model)\n",
    "print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create names and path for model workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedures in this notebook can be run from the notebook or from a batch file by downloading the notebook as a Python script and uncommenting the following code and commenting out the following block. The remainder of the script has to be indented to be included in the loop.  This may require familiarity with Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for pth in dir_list:\n",
    "#     model = os.path.normpath(pth).split(os.sep)[2]\n",
    "#     model_ws = [item for item in dir_list if model in item][0]\n",
    "#     nam_file = '{}.nam'.format(model)\n",
    "#     print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('Reading model information')\n",
    "\n",
    "fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                               load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "dis = fpmg.get_package('DIS')\n",
    "bas = fpmg.get_package('BAS6')\n",
    "upw = fpmg.get_package('UPW')\n",
    "oc = fpmg.get_package('OC')\n",
    "\n",
    "delr = dis.delr\n",
    "delc = dis.delc\n",
    "nlay = dis.nlay\n",
    "nrow = dis.nrow\n",
    "ncol = dis.ncol\n",
    "bot = dis.getbotm()\n",
    "top = dis.gettop()\n",
    "\n",
    "hnoflo = bas.hnoflo\n",
    "ibound = np.asarray(bas.ibound.get_value())\n",
    "hdry = upw.hdry\n",
    "\n",
    "print ('   ... done') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of time in MODFLOW/MODPATH\n",
    "\n",
    "There are several time-related concepts used in MODPATH.\n",
    "* `simulation time` is the elapsed time in model time units from the beginning of the first stress period\n",
    "* `reference time` is an arbitrary value of `simulation time` that is between the beginning and ending of `simulation time`\n",
    "* `tracking time` is the elapsed time relative to `reference time`. It is always positive regardless of whether particles are tracked forward or backward\n",
    "* `release time` is when a particle is released and is specified in `tracking time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup dictionaries of the MODFLOW units for proper labeling of figures.\n",
    "lenunit = {0:'undefined units', 1:'feet', 2:'meters', 3:'centimeters'}\n",
    "timeunit = {0:'undefined', 1:'second', 2:'minute', 3:'hour', 4:'day', 5:'year'}\n",
    "\n",
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days, so enter conversion to days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert string representation of dates into Python datetime objects\n",
    "mf_start_date = dt.datetime.strptime(mf_start_date_str , '%m/%d/%Y')\n",
    "mp_release_date = dt.datetime.strptime(mp_release_date_str , '%m/%d/%Y')\n",
    "\n",
    "# convert simulation time to days from the units specified in the MODFLOW DIS file\n",
    "sim_time = np.append(0, dis.get_totim())\n",
    "sim_time /= time_dict[dis.itmuni]\n",
    "\n",
    "# make a list of simulation time formatted as calendar dates\n",
    "date_list = [mf_start_date + dt.timedelta(days = item) for item in sim_time]\n",
    "\n",
    "# reference time and date are set to the end of the last stress period\n",
    "ref_time = sim_time[-1]\n",
    "ref_date = date_list[-1]\n",
    "\n",
    "# release time is calculated in tracking time (for particle release) and \n",
    "# in simulation time (for identifying head and budget components)\n",
    "release_time_trk = np.abs((ref_date - mp_release_date).days)\n",
    "release_time_sim = (mp_release_date - mf_start_date).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process endpoint information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read endpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# form the path to the endpoint file\n",
    "mpname = '{}_flux'.format(fpmg.name)\n",
    "endpoint_file = '{}.{}'.format(mpname, 'mpend')\n",
    "endpoint_file = os.path.join(model_ws, endpoint_file)\n",
    "\n",
    "ep_data = fit_parametric_distributions.read_endpoints(endpoint_file, dis, time_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit parametric distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample endpoints\n",
    "This next cell takes `s` number of stratified random samples from the endpoints. This is in order to make the curve fitting much faster. 50,000 samples seems to work pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract travel times above num_surf_layers\n",
    "trav_time_raw = ep_data.loc[(ep_data['Initial Layer'] <= num_surf_layers), ['rt']].copy()\n",
    "\n",
    "# sort them\n",
    "trav_time_raw.sort_values('rt', inplace=True)\n",
    "\n",
    "# create arrays of CDF value between 1/x and 1\n",
    "\n",
    "# number of particles above num_surf_layers\n",
    "n = trav_time_raw.shape[0]\n",
    "\n",
    "# number of particles desired to approximate the particle CDF\n",
    "s = 50000\n",
    "\n",
    "ly = np.linspace(1. / s, 1., s, endpoint=True)\n",
    "\n",
    "tt_cdf = np.linspace(1. / n, 1., n, endpoint=True)\n",
    "\n",
    "# log transform the travel times and normalize to porosity\n",
    "tt = np.log(trav_time_raw.rt / por)\n",
    "\n",
    "# interpolate at equally spaced points to reduce the number of particles\n",
    "lprt = np.interp(ly, tt_cdf , tt)\n",
    "\n",
    "first = lprt.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_list = [ss.invgauss, ss.gamma, ss.weibull_min]\n",
    "fit_dict = {}\n",
    "fit_dict[model] = fit_parametric_distributions.fit_dists(ly, lprt, dist_list)\n",
    "\n",
    "dst = os.path.join(model_ws, 'fit_dict_res_all_layers.pickle')\n",
    "with open(dst, 'wb') as f:\n",
    "    pickle.dump(fit_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot CDF and PDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot CDFs for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dst = os.path.join(model_ws, 'RTD')\n",
    "if not os.path.exists(dst):\n",
    "    os.mkdir(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, 'tau.txt')\n",
    "\n",
    "with open(src) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "items = [item.split()[6] for item in lines]\n",
    "\n",
    "tau_glacial = np.float(items [0])\n",
    "tau_bedrock = np.float(items [1])\n",
    "tau_total = np.float(items [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    dist = dist_list[i]\n",
    "    uname = 'uni_{}'.format(dist.name)\n",
    "    aname = 'add_{}'.format(dist.name)\n",
    "    iname = 'imp_{}'.format(dist.name)\n",
    "    fy = 0\n",
    "\n",
    "    part_tt = fit_dict[model]['tt']['rt']\n",
    "    part_cdf = fit_dict[model]['tt']['rt_cdf']\n",
    "    ax.semilogx(np.exp(part_tt), part_cdf, label='Particle', lw=5, color='r', alpha=0.4)\n",
    "    \n",
    "    try:\n",
    "        ep_uni = fit_dict[model]['par'][uname]\n",
    "        uni_cdf = fit_dict[model]['cdf'][uname]\n",
    "        ax.plot(np.exp(part_tt), uni_cdf, label='Parametric CDF: No mixing', color='k', lw=1)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][iname]\n",
    "        imp_cdf = fit_dict[model]['cdf'][iname]\n",
    "        ax.plot(np.exp(part_tt), imp_cdf, label='Parametric CDF: Implicit mixing', color='g', lw=2)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][aname]\n",
    "        fy = ep_exp[6]\n",
    "        add_cdf = fit_dict[model]['cdf'][aname]\n",
    "        ax.plot(np.exp(part_tt), add_cdf, label='Parametric CDF: Explicit mixing', color='r', lw=1)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "            \n",
    "    try:\n",
    "        expon = ss.expon(np.exp(first), tau_glacial)\n",
    "        exx = np.logspace(part_tt.min(), part_tt.max(), 1000)\n",
    "        exy = expon.cdf(exx)\n",
    "        ax.plot(exx / por, exy, label='Calculated exponential CDF', color='b', lw=1, ls='dashed')\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(0.01, 10000)\n",
    "    ax.set_ylim(0, 1)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + 0.15, box.width * 1.10, box.height * 0.8])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Cumulative frequency', fontsize=8)\n",
    "    if i == 1:\n",
    "        ax.set_xlabel('Residence time / porosity, in years', fontsize=8)\n",
    "        ax.legend(loc=0, frameon=False, fontsize=8, handlelength=3, numpoints=1, ncol=2, bbox_to_anchor=(1.6, -0.2))\n",
    "    ax.set_title('{2:}\\n{0:} RTD with {1:0.0f}% RTD$_1$'.format(dist.name, fy*100, model), fontsize=8)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "dst = 'Cumulative RTD for all layers and distributions--{}'.format(model)\n",
    "dst_pth = os.path.join(model_ws, 'RTD', dst)\n",
    "plt.savefig(dst_pth, dpi=300)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PDF for explicit RTD mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "prt = np.exp(lprt)\n",
    "\n",
    "logbins = np.logspace(-4, 4, 100, base=np.e)\n",
    "linbins = np.linspace(0.001, 1000, 100)\n",
    "linbins = np.linspace(-8, 8, 100)\n",
    "freq, bins = np.histogram(lprt, bins=linbins, normed=True)\n",
    "bincen = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    dist = dist_list[i]\n",
    "    dname = 'add_{}'.format(dist.name)\n",
    "    fy = 0\n",
    "\n",
    "    ax.plot(np.exp(bincen), freq, linestyle='None', marker='.', mfc='0.20', mew=0, label='Particle RTD', ms=5)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][dname]\n",
    "        pdf_e_exp = dist(ep_exp[0], ep_exp[1], ep_exp[2]).pdf(lprt) \n",
    "        ax.plot(prt, pdf_e_exp, color='blue', linestyle='dashed', linewidth=1, label='RTD$_1$')\n",
    "        mean_age_early = np.exp((lprt[1:] * pdf_e_exp[1:] * np.diff(lprt)).sum())\n",
    "        ax.axvline(mean_age_early, 0, 0.1, color='blue', label='RTD$_1$ mean age', lw=2)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][dname]\n",
    "        pdf_l_exp = dist(ep_exp[3], ep_exp[4], ep_exp[5]).pdf(lprt) \n",
    "        ax.plot(prt, pdf_l_exp, color='green', linestyle='dashed', linewidth=1, label='RTD$_2$')\n",
    "        mean_age_late = np.exp((lprt[1:] * pdf_l_exp[1:] * np.diff(lprt)).sum())\n",
    "        ax.axvline(mean_age_late, 0, 0.1, color='green', label='RTD$_2$ mean age', lw=2)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][dname]\n",
    "        pdf_e_exp = dist(ep_exp[0], ep_exp[1], ep_exp[2]).pdf(lprt) \n",
    "        pdf_l_exp = dist(ep_exp[3], ep_exp[4], ep_exp[5]).pdf(lprt) \n",
    "        fy = ep_exp[6]\n",
    "        combined_exp = fy * pdf_e_exp + (1 - fy) * pdf_l_exp\n",
    "#         ax.plot(np.exp(lprt), combined_exp, color='r', linestyle='dashed', linewidth=1, label='RTD$_2$')\n",
    "        ax.fill_betweenx(combined_exp, prt, color='r', linewidth=1, label='Composite RTD', alpha=0.3)\n",
    "        mean_age_mixed = np.exp((lprt[1:] * combined_exp[1:] * np.diff(lprt)).sum())\n",
    "        ax.axvline(mean_age_mixed, 0, 0.1, color='red', label='Composite mean age', lw=2)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "   \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(0.01, 10000)\n",
    "    ax.set_ylim(0, 1)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + 0.15, box.width * 1.10, box.height * 0.8])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Density in 1 / years', fontsize=8)\n",
    "    if i == 1:\n",
    "        ax.set_xlabel('Residence time / porosity, in years', fontsize=8)\n",
    "        ax.legend(loc=0, frameon=False, fontsize=8, handlelength=3, numpoints=1, ncol=3, bbox_to_anchor=(1.8, -0.2))\n",
    "    ax.set_title('{2:}\\n{0:} RTD with {1:0.0f}% RTD$_1$'.format(dist.name, fy*100, model), fontsize=8)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    \n",
    "dst = 'Explicit RTD for all layers for each cohort {}'.format(model)\n",
    "dst_pth = os.path.join(model_ws, 'RTD', dst)\n",
    "plt.savefig(dst_pth, dpi=300)\n",
    "# plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PDF for implicit RTD mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "prt = np.exp(lprt)\n",
    "\n",
    "logbins = np.logspace(-4, 4, 100, base=np.e)\n",
    "linbins = np.linspace(0.001, 1000, 100)\n",
    "linbins = np.linspace(-8, 8, 100)\n",
    "freq, bins = np.histogram(lprt, bins=linbins, normed=True)\n",
    "bincen = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(8, 5), sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    dist = dist_list[i]\n",
    "    dname = 'imp_{}'.format(dist.name)\n",
    "    fy = 0\n",
    "\n",
    "    ax.plot(np.exp(bincen), freq, linestyle='None', marker='.', mfc='0.20', mew=0, label='Particle RTD', ms=5)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][dname]\n",
    "        pdf_e_exp = dist(ep_exp[0], ep_exp[1], ep_exp[2]).pdf(lprt) \n",
    "        ax.plot(prt, pdf_e_exp, color='blue', linestyle='dashed', linewidth=1, label='RTD$_1$')\n",
    "        mean_age_early = np.exp((lprt[1:] * pdf_e_exp[1:] * np.diff(lprt)).sum())\n",
    "        ax.axvline(mean_age_early, 0, 0.1, color='blue', label='RTD$_1$ mean age', lw=2)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][dname]\n",
    "        pdf_l_exp = dist(ep_exp[3], ep_exp[4], ep_exp[5]).pdf(lprt) \n",
    "        ax.plot(prt, pdf_l_exp, color='green', linestyle='dashed', linewidth=1, label='RTD$_2$')\n",
    "        mean_age_late = np.exp((lprt[1:] * pdf_l_exp[1:] * np.diff(lprt)).sum())\n",
    "        ax.axvline(mean_age_late, 0, 0.1, color='green', label='RTD$_2$ mean age', lw=2)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        ep_exp = fit_dict[model]['par'][dname]\n",
    "        pdf_e_exp = dist(ep_exp[0], ep_exp[1], ep_exp[2]).pdf(lprt) \n",
    "        pdf_l_exp = dist(ep_exp[3], ep_exp[4], ep_exp[5]).pdf(lprt) \n",
    "        combined_exp = pdf_e_exp / (1 + pdf_e_exp - pdf_l_exp)\n",
    "        ax.fill_betweenx(combined_exp, prt, color='r', linewidth=1, label='Composite RTD', alpha=0.3)\n",
    "        mean_age_mixed = np.exp((lprt[1:] * combined_exp[1:] * np.diff(lprt)).sum())\n",
    "        ax.axvline(mean_age_mixed, 0, 0.1, color='red', label='Composite mean age', lw=2)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "   \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(0.01, 10000)\n",
    "    ax.set_ylim(0, 1)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + 0.15, box.width * 1.10, box.height * 0.8])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Density in 1 / years', fontsize=8)\n",
    "    if i == 1:\n",
    "        ax.set_xlabel('Residence time / porosity, in years', fontsize=8)\n",
    "        ax.legend(loc=0, frameon=False, fontsize=8, handlelength=3, numpoints=1, ncol=3, bbox_to_anchor=(1.8, -0.2))\n",
    "    ax.set_title('{2:}\\n{0:} RTD with {1:} RTD'.format(dist.name, 'implicit', model), fontsize=8)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    \n",
    "dst = 'Implicit RTD for all layers for each cohort {}'.format(model)\n",
    "dst_pth = os.path.join(model_ws, 'RTD', dst)\n",
    "plt.savefig(dst_pth, dpi=300)\n",
    "# plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 8,\n",
    "        'sans-serif' : 'Arial'}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "prt = np.exp(lprt)\n",
    "\n",
    "logbins = np.logspace(-4, 4, 100, base=np.e)\n",
    "linbins = np.linspace(0.001, 1000, 100)\n",
    "linbins = np.linspace(-8, 8, 100)\n",
    "freq, bins = np.histogram(lprt, bins=linbins, normed=True)\n",
    "bincen = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.8, 4.6), sharey=True)\n",
    "\n",
    "dist = dist_list[2]\n",
    "dname = 'add_{}'.format(dist.name)\n",
    "fy = 0\n",
    "\n",
    "ax.plot(np.exp(bincen), freq, linestyle='None', marker='.', mfc='0.20', mew=0, label='Particle RTD', ms=5)\n",
    "\n",
    "try:\n",
    "    ep_exp = fit_dict[model]['par'][dname]\n",
    "    pdf_e_exp = dist(ep_exp[0], ep_exp[1], ep_exp[2]).pdf(lprt) \n",
    "    ax.plot(prt, pdf_e_exp, color='blue', linestyle='dashed', linewidth=1, label='RTD$_1$')\n",
    "    mean_age_early = np.exp((lprt[1:] * pdf_e_exp[1:] * np.diff(lprt)).sum())\n",
    "    ax.axvline(mean_age_early, 0, 0.1, color='blue', label='RTD$_1$ mean age', lw=2)\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    ep_exp = fit_dict[model]['par'][dname]\n",
    "    pdf_l_exp = dist(ep_exp[3], ep_exp[4], ep_exp[5]).pdf(lprt) \n",
    "    ax.plot(prt, pdf_l_exp, color='green', linestyle='dashed', linewidth=1, label='RTD$_2$')\n",
    "    mean_age_late = np.exp((lprt[1:] * pdf_l_exp[1:] * np.diff(lprt)).sum())\n",
    "    ax.axvline(mean_age_late, 0, 0.1, color='green', label='RTD$_2$ mean age', lw=2)\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    ep_exp = fit_dict[model]['par'][dname]\n",
    "    pdf_e_exp = dist(ep_exp[0], ep_exp[1], ep_exp[2]).pdf(lprt) \n",
    "    pdf_l_exp = dist(ep_exp[3], ep_exp[4], ep_exp[5]).pdf(lprt) \n",
    "    fy = ep_exp[6]\n",
    "    combined_exp = fy * pdf_e_exp + (1 - fy) * pdf_l_exp\n",
    "    ax.fill_betweenx(combined_exp, prt, color='r', linewidth=1, label='Composite RTD', alpha=0.3)\n",
    "    mean_age_mixed = np.exp((lprt[1:] * combined_exp[1:] * np.diff(lprt)).sum())\n",
    "    ax.axvline(mean_age_mixed, 0, 0.1, color='red', label='Composite mean age', lw=2)\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(1, 10000)\n",
    "ax.set_ylim(0, 0.8)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + 0.15, box.width * 1.10, box.height * 0.8])\n",
    "ax.set_ylabel('Density in 1 / years', fontsize=8)\n",
    "ax.set_xlabel('Residence time / porosity in years', fontsize=8)\n",
    "ax.legend(loc=0, frameon=False, fontsize=8, handlelength=3, numpoints=1, ncol=3, bbox_to_anchor=(1.8, -0.2))\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "form_list = ['png', 'pdf', 'tif']\n",
    "for form in form_list:\n",
    "    line = 'Paper #2017WR021531-f06.{}'.format(form)\n",
    "    fig_name = os.path.join(fig_dir, line)\n",
    "    plt.savefig(fig_name, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on RTD parent distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Stack Exchange Cross Validated:\n",
    "\n",
    "Both the gamma and Weibull distributions can be seen as generalisations of the exponential distribution. If we look at the exponential distribution as describing the waiting time of a Poisson process (the time we have to wait until an event happens, if that event is equally likely to occur in any time interval), then the $\\Gamma(k, \\theta)$ distribution describes the time we have to wait for $k$ independent events to occur.\n",
    "\n",
    "On the other hand, the Weibull distribution effectively describes the time we have to wait for one event to occur, if that event becomes more or less likely with time. Here the $k$ parameter describes how quickly the probability ramps up (proportional to $t^{kâˆ’1}$).\n",
    "\n",
    "We can see the difference in effect by looking at the pdfs of the two distributions. Ignoring all the normalising constants:\n",
    "\n",
    "$f_\\Gamma(x)\\propto x^{k-1}\\exp(-\\frac{x}{\\theta})$\n",
    "\n",
    "$f_W(x)\\propto x^{k-1}\\exp(-{(\\frac{x}{\\lambda})^k)}$\n",
    "\n",
    "The Weibull distribution drops off much more quickly (for $k>1$) or slowly (for $k<1$) than the gamma distribution. In the case where $k=1$, they both reduce to the exponential distribution.\n",
    "\n",
    "From Wikipedia:\n",
    "\n",
    "The generalized gamma has three parameters: $a>0$, $d>0$, and $p>0$. For non-negative x, the probability density function of the generalized gamma is$^{[2]}$\n",
    "\n",
    "$f(x;a,d,p)={\\frac  {(p/a^{d})x^{{d-1}}e^{{-(x/a)^{p}}}}{\\Gamma (d/p)}},$\n",
    "\n",
    "where $\\Gamma (\\cdot )$ denotes the gamma function.\n",
    "\n",
    "The cumulative distribution function is\n",
    "$F(x;a,d,p)={\\frac  {\\gamma (d/p,(x/a)^{p})}{\\Gamma (d/p)}},$\n",
    "\n",
    "where $\\gamma (\\cdot )$ denotes the lower incomplete gamma function.\n",
    "\n",
    "If $d=p$ then the generalized gamma distribution becomes the Weibull distribution. Alternatively, if $p=1$ the generalised gamma becomes the gamma distribution.\n",
    "\n",
    "From NIST National Engineering Handbook\n",
    "\n",
    "The formula for the probability density function of the general Weibull distribution is\n",
    "\n",
    "$f(x)=\\frac\\gamma\\alpha(\\frac{x-\\mu}\\alpha)^{(\\gamma-1)}\\exp(-(\\frac{(x-\\mu)}\\alpha)^\\gamma)$\n",
    "\n",
    "$x\\ge\\mu; \\gamma,\\alpha>0$\n",
    "\n",
    "where $\\gamma$ is the shape parameter, $\\mu$ is the location parameter and $\\alpha$ is the scale parameter. The case where $\\mu = 0$ and $\\alpha = 1$ is called the standard Weibull distribution. The case where $\\mu = 0$ is called the 2-parameter Weibull distribution. The equation for the standard Weibull distribution reduces to\n",
    "\n",
    "$f(x)=\\gamma x^{(\\gamma-1)}\\exp(-(x^\\gamma))$\n",
    "\n",
    "Since the general form of probability functions can be expressed in terms of the standard distribution, all subsequent formulas in this section are given for the standard form of the function.\n",
    "\n",
    "The general formula for the probability density function of the gamma distribution is\n",
    "\n",
    "$f(x)=\\frac{(\\frac{x-\\mu}{\\beta})^{\\gamma-1}\\exp(-\\frac{x-\\mu}{\\beta})}{\\beta\\Gamma(\\gamma)}$\n",
    "\n",
    "where $\\gamma$ is the shape parameter, $\\mu$ is the location parameter, $\\alpha$ is the scale parameter, and $\\Gamma$ is the gamma function which has the formula\n",
    "\n",
    "$\\Gamma(a)=\\int_0^\\infty t^{a-1}e^{-t}dt$\n",
    "\n",
    "The case where $\\mu=0$ and $\\beta=1$ is called the standard gamma distribution. The equation for the standard gamma distribution reduces to\n",
    "\n",
    "$f(x)=\\frac{x^{\\gamma-1}\\exp(-x)}{\\Gamma(\\gamma)}$\n",
    "\n",
    "  \n",
    "Since the general form of probability functions can be expressed in terms of the standard distribution, all subsequent formulas in this section are given for the standard form of the function."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
