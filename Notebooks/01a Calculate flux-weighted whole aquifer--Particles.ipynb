{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebooks 01a and 01b are used together to get residence-time distribution (RTD) for the entire aquifer from an existing MODFLOW model. It is possible to read in any group or label from a 3D array and make RTDs for those groups. The approach is to \n",
    "* read an existing model\n",
    "* create flux-weighted particle starting locations in every cell\n",
    "* run MODPATH and read endpoints\n",
    "* fit parametric distributions to endpoints\n",
    "\n",
    "Notebook 01a (this notebook) creates flux-weighted particles and runs MODPATH.  Notebook 01b fits parametric distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import flopy as fp\n",
    "import imeth\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined variables\n",
    "\n",
    "**IMPORTANT** \n",
    "\n",
    "The directory name where the model is has to be the same as the base name of the MODFLOW name file.\n",
    "\n",
    "**Time specification**\n",
    "\n",
    "MODFLOW and MODPATH use elapsed time and are not aware of calendar time. To place MODFLOW/MODPATH elapsed time on the calendar, two calendar dates are specified at the top of the notebook: the beginning of the first stress period (`mf_start_date`) and when particles are to be released (`mp_release_date`). The latter date could be used in many ways, for example to represent a sampling date, or it could be looped over to create a time-lapse set of ages. \n",
    "\n",
    "There are several time-related definitons used in MODPATH.\n",
    "* `simulation time` is the elapsed time in model time units from the beginning of the first stress period\n",
    "* `reference time` is an arbitrary value of `simulation time` that is between the beginning and ending of `simulation time`\n",
    "* `tracking time` is the elapsed time relative to `reference time`. It is always positive regardless of whether particles are tracked forward or backward\n",
    "* `release time` is when a particle is released and is specified in `tracking time`\n",
    "\n",
    "Particles will be released on the date `mp_release_date_str` relative to the starting time `mf_start_date_str`. The latter date is arbitrary; it is used to set the calendar date for the beginning of the first stress period. The length of the first stress period, even though it is usualy steady state, should correspond to the length of time between `mf_start_date_str` and the start of the first transient stress period. The notebook will calculate `release time` in units of `tracking time` for the `mp_release_date`.\n",
    "\n",
    "`layer_for_flow_calc` is an arbitrary layer number on which to divide the model domain for calculating RTDs. For example, in glacial aquifers it could represent the layer number of the bottom of unconsolidated deposits. In that case, anything below this layer could be considered bedrock.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through home directory to get list of name files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# The directories in the following list will be searched for models\n",
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6x64.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2018' \n",
    "\n",
    "# Read the zone array:\n",
    "# use 'None' if there is no zone array\n",
    "# the zone array should be either a comma-delimited file (.csv) with dimensions\n",
    "# (nrow * ncol, nlay) or a compressed numpy array (.npz) with dimensions (nlay, nrow, ncol).\n",
    "# The file with this name has to be in the model workspace directory defined later\n",
    "zone_array_file = 'fz_zones_v2.csv'\n",
    "\n",
    "# The total net flow across the layer boundary specified below will be calculated and reported.\n",
    "layer_for_flow_calc = 3\n",
    "\n",
    "# The zone number will be encoded in the MODPATH endpoint file under the \"Label\" variable.\n",
    "# The RTD for all zones will be calculated if use_all_zones is True.\n",
    "# You can also calculate RTDs groups of zones.\n",
    "use_all_zones = True\n",
    "use_groups_of_zones = True\n",
    "number_of_particles_per_group = 1.0E+06\n",
    "\n",
    "# If zones are to be grouped, put the zone numbers in a list inside a tuple.\n",
    "# You can have more than one group.\n",
    "# Zones can be part of more than one group and not all zones have to be used,\n",
    "# e.g. zones_to_group = ([4, 5, 6], [41]).  If only one group is used, put a comma \n",
    "# after it, e.g. zones_to_group = ([41],)\n",
    "zones_to_group = ([15],)\n",
    "\n",
    "num_cells2budchk = 10\n",
    "\n",
    "# weighting scheme\n",
    "weight_scheme = 'flow'\n",
    "# weight_scheme = 'volume'\n",
    "\n",
    "por = 0.20\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    mod_list.append(mod)\n",
    "                    dir_list.append(dirpath)\n",
    "                    i += 1\n",
    "print('    {} models read'.format(i))\n",
    "\n",
    "model_area = Dropdown(\n",
    "    options=mod_list,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)\n",
    "\n",
    "with open('dir_list.txt', 'w') as f:\n",
    "    for i in dir_list:\n",
    "        f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create names and path for model workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedures in this notebook can be run from the notebook or from a batch file by downloading the notebook as a Python script and uncommenting the following code and commenting out the following block. The remainder of the script has to be indented to be included in the loop.  This may require familiarity with Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pth in dir_list:\n",
    "#     model = os.path.normpath(pth).split(os.sep)[2]\n",
    "#     model_ws = [item for item in dir_list if model in item][0]\n",
    "#     nam_file = '{}.nam'.format(model)\n",
    "#     print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_area.value\n",
    "model_ws = [item for item in dir_list if model in item][0]\n",
    "nam_file = '{}.nam'.format(model)\n",
    "print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('Reading model information')\n",
    "\n",
    "fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                               load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "dis = fpmg.get_package('DIS')\n",
    "bas = fpmg.get_package('BAS6')\n",
    "upw = fpmg.get_package('UPW')\n",
    "oc = fpmg.get_package('OC')\n",
    "\n",
    "delr = dis.delr\n",
    "delc = dis.delc\n",
    "nlay = dis.nlay\n",
    "nrow = dis.nrow\n",
    "ncol = dis.ncol\n",
    "bot = dis.getbotm()\n",
    "top = dis.gettop()\n",
    "\n",
    "hnoflo = bas.hnoflo\n",
    "ibound = np.asarray(bas.ibound.get_value())\n",
    "hdry = upw.hdry\n",
    "\n",
    "print ('   ... done') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FloPy loads MODFLOW packages but not their name-file unit numbers, so these have to be read separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, fpmg.namefile)\n",
    "name_file_df = pd.read_table(src, header=None, comment='#', delim_whitespace=True, \n",
    "              names=['package', 'unit', 'filename', 'type'])\n",
    "\n",
    "name_file_df['package'] = name_file_df.package.str.lower()\n",
    "name_file_df.set_index('unit', inplace=True)\n",
    "\n",
    "head_file_name = name_file_df.loc[oc.iuhead, 'filename']\n",
    "bud_file_name = name_file_df.loc[oc.get_budgetunit(), 'filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read head and budget  file headers\n",
    "The head file is used limit particle placement to the saturated part of each cell and to identify dry cells. Is it also use to define time increments in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, head_file_name)\n",
    "hd_obj = fp.utils.HeadFile(src)\n",
    "head_df = pd.DataFrame(hd_obj.recordarray)\n",
    "\n",
    "src = os.path.join(model_ws, bud_file_name)\n",
    "bud_obj = fp.utils.CellBudgetFile(src)\n",
    "all_bud_df = pd.DataFrame(bud_obj.recordarray)\n",
    "\n",
    "# convert to zero base\n",
    "all_bud_df['kper'] -= 1\n",
    "all_bud_df['kstp'] -= 1\n",
    "head_df['kper'] -= 1\n",
    "head_df['kstp'] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of time in MODFLOW/MODPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify time step and stress period for particle release\n",
    "\n",
    "* read all stress periods and time steps that were preserved in the budget file\n",
    "* find the largest (latest) stress period and time step that include the mp_release_date\n",
    "* make a subset of all the budget records from the specified period and step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0\n",
    "\n",
    "# convert string representation of dates into Python datetime objects\n",
    "mf_start_date = dt.datetime.strptime(mf_start_date_str , '%m/%d/%Y')\n",
    "mp_release_date = dt.datetime.strptime(mp_release_date_str , '%m/%d/%Y')\n",
    "\n",
    "# check to make sure they are valid\n",
    "assert mf_start_date < mp_release_date, 'The particle release date has \\\n",
    "to be after the start of the MODFLOW simulation'\n",
    "\n",
    "# group by period and step\n",
    "kdf = all_bud_df.groupby(['kper', 'kstp']).median()\n",
    "kdf = kdf[['pertim', 'totim']]\n",
    "\n",
    "# make a datetime series for timesteps starting with 0\n",
    "# totim is elapsed time in simulation time\n",
    "end_date = mf_start_date + pd.to_timedelta(np.append(0, kdf.totim), unit='days')\n",
    "end_date = end_date.map(lambda t: t.strftime('%Y-%m-%d %H:%M'))\n",
    "kdf.loc[:, 'start_date'] = end_date[0:-1]\n",
    "kdf.loc[:, 'end_date'] = end_date[1:]\n",
    "\n",
    "# make a datetime series for timesteps starting with 0\n",
    "# totim is elapsed time in simulation time\n",
    "# reformat the dates to get rid of seconds\n",
    "end_date = mf_start_date + pd.to_timedelta(np.append(0, kdf.totim), unit='days')\n",
    "kdf.loc[:, 'start_date'] = end_date[0:-1].map(lambda t: t.strftime('%Y-%m-%d %H:%M'))\n",
    "kdf.loc[:, 'end_date'] = end_date[1:].map(lambda t: t.strftime('%Y-%m-%d %H:%M'))\n",
    "\n",
    "# reference time and date are set to the end of the last stress period\n",
    "ref_time = kdf.totim.max()\n",
    "ref_date = end_date.max()\n",
    "\n",
    "# release time is calculated in tracking time (for particle release) and \n",
    "# in simulation time (for identifying head and budget components)\n",
    "release_time_trk = np.abs((ref_date - mp_release_date).days)\n",
    "release_time_sim = (mp_release_date - mf_start_date).days\n",
    "\n",
    "# find the latest group index that includes the release date\n",
    "idx = (kdf.totim >= release_time_sim).idxmax()\n",
    "kdf.loc[idx, 'particle_release'] = True\n",
    "\n",
    "# switch period and step \n",
    "kstpkper = (idx[1], idx[0])\n",
    "\n",
    "assert ref_date > mp_release_date, 'The reference date has \\\n",
    "to be after the particle release'\n",
    "\n",
    "dst = os.path.join(model_ws, 'time_summary.csv')\n",
    "kdf.to_csv(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = hd_obj.get_data(kstpkper=kstpkper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate saturated thickness and volume for each cell.\n",
    "* create 3D model cell boundary grid\n",
    "* saturated top in cell is minimum of head or cell top\n",
    "* saturated thickness is the distance between the saturated top and cell bottom\n",
    "* if the cell is dry or inactive, the saturated thickness is zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a 3D array of layer boundaries\n",
    "grid = np.zeros((nlay+1, nrow, ncol))\n",
    "grid[0, :, :] = top\n",
    "grid[1:, :, :] = bot\n",
    "\n",
    "# tmp is the minimum of the head and cell top \n",
    "tmp = np.minimum(heads, grid[:-1, :, :])\n",
    "\n",
    "# the saturated thickness is first estimated to be the difference between tmp and the cell bottom\n",
    "sat_thk_cell = (tmp - grid[1:, :, :]) \n",
    "\n",
    "# sat_thk_cell < 0 means the head is below the bottom of the cell; these are set to zero\n",
    "sat_thk_cell[sat_thk_cell < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mean exponential age by zone\n",
    "\n",
    "Based on simulated recharge volumteric rate and simulated aquifer volume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Read zone array to use as particle label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_array_src = os.path.join(model_ws, zone_array_file)\n",
    "\n",
    "if 'None' not in zone_array_src:\n",
    "    ext = os.path.splitext(zone_array_src)[1].lower()\n",
    "    if ext == '.csv':\n",
    "        zones = pd.read_csv(zone_array_src, header=0)\n",
    "        zones = zones.unstack().values.reshape(nlay, nrow, ncol)\n",
    "        print('Zones read from csv file')\n",
    "    elif (ext == '.zon') | (ext == '.zone'):\n",
    "        # option to read zones from a MODFLOW zone package file not implemented\n",
    "        print('Zones read from MODFLOW zone array')\n",
    "        pass \n",
    "    elif ext == '.npz':\n",
    "        print('Zones read from compressed numpy array object')\n",
    "        np.save()\n",
    "        d = np.load(zone_array_src)\n",
    "        if len(d.items()) != 1:\n",
    "            print('There should only be one item type in the npz file and ')\n",
    "            print('it should be an array dimensioned as (nlay, nrow, ncol)')\n",
    "        else:\n",
    "            zones = d.items()[0][1]\n",
    "else:\n",
    "    print('No zone information read')\n",
    "    zones = np.ones((nlay * nrow * ncol))\n",
    "\n",
    "# make a data frame to store group id \n",
    "zones = zones.ravel()\n",
    "zone_df = pd.DataFrame(index=np.arange(zones.shape[0]))\n",
    "\n",
    "group_column_list = list()\n",
    "zone_list_arr = np.unique(zones)\n",
    "\n",
    "if use_all_zones:\n",
    "    group_column_list.append('all_zones')\n",
    "    zone_df.loc[:, 'all_zones'] = True\n",
    "    num_of_zones = zone_list_arr.shape[0]\n",
    "else:\n",
    "    num_of_zones = 0\n",
    "\n",
    "if use_groups_of_zones:\n",
    "    for zone_group in zones_to_group:\n",
    "        gp_label = 'zones{}'.format(zone_group)\n",
    "        gp_label = gp_label.replace(', ', '_')\n",
    "        group_column_list.append(gp_label)\n",
    "        zone_df.loc[:, gp_label] = False\n",
    "        for zon in zone_group:\n",
    "            zone_df.loc[zones.ravel() == zon, gp_label] = True\n",
    "    num_of_groups = len(zones_to_group)\n",
    "else:\n",
    "    num_of_groups = 0\n",
    "    \n",
    "dst = os.path.join(model_ws, 'zone_df.csv')\n",
    "zone_df.to_csv(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MODPATH input files and run MODPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate inflow into each cell\n",
    "The number of particles in each cell is in proportion to the flux into the cell. Particle locations within a cell are generated randomly. Number of particles per cell is proportional to the flow into the cell such that the total number of particles = `t_num_parts`, in this case 2 million. \n",
    "\n",
    "MODFLOW includes a variable called `imeth` in the budget file. `imeth` is used to specify the format in which the budget data are stored. Functions for reading `imeth` for each of the data formats are defined in the module imeth.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract the budget records for the specified period and step\n",
    "bud_df = all_bud_df.query('kstp=={} and kper=={}'.format(*kstpkper)).copy()\n",
    "\n",
    "bud_df.loc[:, 'per_num'] = bud_df.totim.factorize()[0]\n",
    "num_rec = bud_df.shape[0]\n",
    "\n",
    "flow_times = bud_df.totim.unique()\n",
    "nt = bud_df.per_num.nunique()\n",
    "\n",
    "rxc = dis.nrow * dis.ncol\n",
    "nn = dis.nlay * rxc\n",
    "\n",
    "im = imeth.imeth(nlay, nrow, ncol)\n",
    "\n",
    "qx1 = np.zeros((nt, nn))\n",
    "qx2 = np.zeros_like(qx1)\n",
    "qy1 = np.zeros_like(qx1)\n",
    "qy2 = np.zeros_like(qx1)\n",
    "qz1 = np.zeros_like(qx1)\n",
    "qz2 = np.zeros_like(qx1)\n",
    "storage = np.zeros_like(qx1)\n",
    "\n",
    "bound_flow = np.zeros((nn, 7))\n",
    "int_flow_right = np.zeros((nn))\n",
    "int_flow_left = np.zeros((nn))\n",
    "int_flow_front = np.zeros((nn))\n",
    "int_flow_back = np.zeros((nn))\n",
    "int_flow_lower = np.zeros((nn))\n",
    "int_flow_top = np.zeros((nn))\n",
    "\n",
    "for i, rec in bud_df.iterrows():\n",
    "\n",
    "    BUFF = bud_obj.get_record(i)\n",
    "    \n",
    "    internal_flow_list = [b'   CONSTANT HEAD', b'FLOW RIGHT FACE ', b'FLOW FRONT FACE ', b'FLOW LOWER FACE ', b'STORAGE']\n",
    "\n",
    "    if rec.text in internal_flow_list:\n",
    "        if b'   CONSTANT HEAD' in rec.text:\n",
    "            bound_flow += im.imeth2(BUFF)\n",
    "        elif b'FLOW RIGHT FACE ' in rec.text:\n",
    "            int_flow_right = im.imeth1(BUFF)\n",
    "            int_flow_left = np.roll(int_flow_right, 1)\n",
    "        elif b'FLOW FRONT FACE ' in rec.text:\n",
    "            int_flow_front = im.imeth1(BUFF)\n",
    "            int_flow_back = np.roll(int_flow_front, ncol)\n",
    "        elif b'FLOW LOWER FACE ' in rec.text:\n",
    "            int_flow_lower = im.imeth1(BUFF)\n",
    "            int_flow_top = np.roll(int_flow_lower, rxc)\n",
    "        elif b'STORAGE' in rec.text:\n",
    "            bound_flow[: , 0] += im.imeth1(BUFF)\n",
    "        else:\n",
    "            print('Unrecognized budget type')\n",
    "\n",
    "    if rec.text not in internal_flow_list:\n",
    "        if rec.imeth == 1:\n",
    "            bound_flow[:, 0] += im.imeth1(BUFF)\n",
    "        elif rec.imeth == 2:\n",
    "            bound_flow[:, 0] += im.imeth2(BUFF)\n",
    "        elif rec.imeth == 3:\n",
    "            bound_flow += im.imeth3(BUFF)\n",
    "        elif rec.imeth == 4:\n",
    "            bound_flow += im.imeth4(BUFF)\n",
    "        elif rec.imeth == 5:\n",
    "            bound_flow += im.imeth5(BUFF)\n",
    "        else:\n",
    "            print('Unrecognized budget type')\n",
    "\n",
    "    storage[rec.per_num , :] += bound_flow[:, 0]\n",
    "\n",
    "    qx1[rec.per_num , :] = int_flow_left + bound_flow[:, 1]\n",
    "    qx2[rec.per_num , :] = int_flow_right - bound_flow[:, 2]\n",
    "\n",
    "    qy1[rec.per_num , :] = -int_flow_front + bound_flow[:, 3]\n",
    "    qy2[rec.per_num , :] = -int_flow_back - bound_flow[:, 4]\n",
    "\n",
    "    qz1[rec.per_num , :] = -int_flow_lower + bound_flow[:, 5]\n",
    "    qz2[rec.per_num , :] = -int_flow_top - bound_flow[:, 6]\n",
    "\n",
    "qin1 = np.where(qx1 > 0, qx1, 0)\n",
    "qin2 = np.where(qx2 < 0, -qx2, 0)\n",
    "qin3 = np.where(qy1 > 0, qy1, 0)\n",
    "qin4 = np.where(qy2 < 0, -qy2, 0)\n",
    "qin5 = np.where(qz1 > 0, qz1, 0)\n",
    "qin6 = np.where(qz2 < 0, -qz2, 0)\n",
    "\n",
    "flow_sum = np.sum((qin1, qin2, qin3, qin4, qin5, qin6), axis=0)\n",
    "\n",
    "# set the flow to zero for cells that went dry during the simulation and also for isolated cells\n",
    "flow_sum[0, heads.ravel() == hdry] = 0\n",
    "# flow_sum[heads.ravel() > 1.E+29] = 0\n",
    "\n",
    "print ('   ... done'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract specified flows from MODFLOW budget\n",
    "\n",
    "Get recharge at top model surface (recharge package only at this time) and flow across the bottom of of the layer in `layer_for_flow_calc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if b'        RECHARGE' in bud_df.text.values:\n",
    "    # probably should make this so that recharge is summed from the highest active cell\n",
    "    rch = bud_obj.get_data(text='RECHARGE', kstpkper=kstpkper, full3D=True)\n",
    "    recharge_vol = rch[0].sum()  \n",
    "else:\n",
    "    print('no recharge')\n",
    "# This assumes all recharge is from RCH package. Should add a check for UZF package & concat them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell can be used to write all the budget components for the whole model into a dataframe that will be stored as a csv file.  The file may be quite large for big models, so the cell is commented out by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "\n",
    "for i, j in bud_df.iterrows():\n",
    "    tmp_df[j.text] = bud_obj.get_data(text=j.text, kstpkper=kstpkper, full3D=True)[0].ravel()\n",
    "    \n",
    "dst = os.path.join(model_ws, 'all_cells_budget.csv')\n",
    "tmp_df.to_csv(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if layer_for_flow_calc <= nlay:  \n",
    "    flf = bud_obj.get_data(text='FLOW LOWER FACE', kstpkper=kstpkper, full3D=True)\n",
    "    flow_below_layer = flf[0][layer_for_flow_calc - 1, :, :]\n",
    "    total_bedrock_recharge_vol = flow_below_layer[flow_below_layer > 0].sum()\n",
    "    total_bedrock_recharge_frac = total_bedrock_recharge_vol / recharge_vol\n",
    "else:\n",
    "    print('invalid layer_for_flow_calc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create grid cell dimension arrays\n",
    "delc_ar, dum, delr_ar = np.meshgrid(delc, np.arange(nlay), delr)\n",
    "\n",
    "# saturated volume of each cell for the current zone\n",
    "sat_vol_cell = sat_thk_cell * delc_ar * delr_ar\n",
    "\n",
    "tau_df = pd.DataFrame(index=group_column_list)\n",
    "dst = os.path.join(model_ws, 'tau.txt')\n",
    "for group in zone_df:\n",
    "    \n",
    "    sat_vol = sat_vol_cell.ravel()[zone_df[group]].sum()\n",
    "    recharge = flow_sum[0, zone_df[group]].sum()\n",
    "\n",
    "    tau_df.loc[group, 'sat_vol'] = sat_vol\n",
    "    tau_df.loc[group, 'recharge'] = recharge\n",
    "    tau_df.loc[group, 'tau'] = sat_vol * por / recharge /  365.25\n",
    "    tau_df.loc[group, 'rech_volume'] = total_bedrock_recharge_vol\n",
    "    tau_df.loc[group, 'rech_fraction'] = total_bedrock_recharge_frac\n",
    "    \n",
    "with open(dst, 'w') as f:\n",
    "    tau_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat cell coordinates for the number of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random particle placement in the saturated part of each cell\n",
    "\n",
    "MODPATH wants particle locations as the layer, row, column (which we now have) plus the relative cell coordinates within each cell over (0, 1). In this application relative cell coordinates are generated randomly. In convertible cells (i.e., in a water table layer) MODPATH treats the water table as the top of the cell. In other words, the water table is at 1.0 in relative cell coordinates. In non-convertible cells, the top of the cell is at 1.0. Thus, in partially saturated cells, the random particle location is scaled to the saturated thickness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify seed for random number generator--could be any integer value\n",
    "prng = np.random.RandomState(2909591)\n",
    "bud_chk_dict = dict()\n",
    "\n",
    "for group in zone_df:\n",
    "    \n",
    "    # switch the commenting of the following 2 lines to switch from volume weighted to flow weighted \n",
    "    if weight_scheme == 'flow':\n",
    "        weight = flow_sum[0, zone_df[group]]\n",
    "        weight_label = 'flux'\n",
    "    elif weight_scheme == 'volume':\n",
    "        weight = sat_vol_cell.ravel()[zone_df[group]]\n",
    "        weight_label = 'volume'\n",
    "\n",
    "    f = number_of_particles_per_group / weight.sum()\n",
    "\n",
    "    parts_per_cell = np.rint( weight * f ).astype( np.int32 )\n",
    "\n",
    "    l, r, c = np.indices(( nlay, nrow, ncol ))\n",
    "    l= l.ravel()[zone_df[group]]\n",
    "    r= r.ravel()[zone_df[group]]\n",
    "    c= c.ravel()[zone_df[group]]\n",
    "    label = zones[zone_df[group]]\n",
    "\n",
    "    lrep = np.repeat( l, parts_per_cell.ravel() )\n",
    "    rrep = np.repeat( r, parts_per_cell.ravel() )\n",
    "    crep = np.repeat( c, parts_per_cell.ravel() )\n",
    "    label = np.repeat( label, parts_per_cell.ravel() )\n",
    "    num_parts = lrep.shape[0]\n",
    "    \n",
    "    # generate random relative coordinates within a cell in 3D\n",
    "    cell_coords = prng.rand( num_parts, 3 )\n",
    "    \n",
    "    grp = 1\n",
    "\n",
    "    particles = np.zeros( ( num_parts, 11 ) )\n",
    "    particles[:, 0] = np.arange( 1, num_parts + 1 )\n",
    "    particles[:, 1] = grp\n",
    "    particles[:, 2] = 1\n",
    "    particles[:, 3] = lrep + 1\n",
    "    particles[:, 4] = rrep + 1\n",
    "    particles[:, 5] = crep + 1\n",
    "    particles[:, 6:9] = cell_coords\n",
    "    particles[:, 9] = release_time_trk\n",
    "    particles[:, 10] = label\n",
    "    \n",
    "    print('Write starting locations for {}'.format(group))\n",
    "\n",
    "    line = '{:5d}\\n{:5d}\\n'.format(1, 1)\n",
    "    line = line + 'group_{}\\n'.format(1)\n",
    "    npart = particles.shape[0]\n",
    "    line = line + '{:6d}'.format(npart)\n",
    "    dst_pth = os.path.join(model_ws, '{}_{}_{}.loc'.format(fpmg.name, weight_label, group))\n",
    "    form = '%6d %6d %3d %3d %3d %3d %12.9f %12.9f %12.9f %12.9e %15.3f'\n",
    "    np.savetxt(dst_pth, particles, delimiter=' ', fmt=form, header=line, comments='')\n",
    "\n",
    "    print('   Total particles in \"{}\" is {}'.format(group, num_parts))\n",
    "    print('   Min particles per cell in {} = {:10.0f}'.format(group, parts_per_cell.min()))\n",
    "    print('   Mean particles per cell in {} = {:10.0f}'.format(group, parts_per_cell.mean()))\n",
    "    print('   Max particles per cell in {} = {:10.0f}'.format(group, parts_per_cell.max()))\n",
    "    a, b = np.histogram(particles[:, 3], bins= np.arange(1, nlay+2))\n",
    "    tdf = pd.DataFrame({'Number of particles' : a}, index=pd.Index(b[:-1], name='Layer') )\n",
    "    print(tdf)\n",
    "    \n",
    "    print ('   ... done') \n",
    "    \n",
    "    A = (particles[:, 3:6] - 1)\n",
    "    A = A[prng.choice(A.shape[0], num_cells2budchk, replace=False), :]\n",
    "    budchk = np.ones((num_cells2budchk, 4))\n",
    "    budchk[:, 1:] = A\n",
    "    budchk = budchk.astype(np.int32())\n",
    "        \n",
    "    def seq(item):\n",
    "        return item[1] * nrow * ncol + item[2] * ncol + item[3] \n",
    "    t_df = pd.DataFrame(budchk, columns=('Grid', 'Layer', 'Row', 'Column'))\n",
    "    t_df['seqnum'] = np.array([seq(item) for item in budchk])\n",
    "    t_df['flow_sum'] = flow_sum[0, t_df['seqnum']]\n",
    "    t_df['qz2'] = qz2[0, t_df['seqnum']]\n",
    "\n",
    "    bud_chk_dict[group] = t_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MODPATH and read endpoint information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get random cells to check budget computations\n",
    "Select 10 random active cells to check cell budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MODPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('   Write and run MODPATH')\n",
    "\n",
    "# prepare Modpath files   \n",
    "SimulationType = 1              # 1 endpoint; 2 pathline; 3 timeseries\n",
    "TrackingDirection = 2           # 1 forward; 2 backward\n",
    "WeakSinkOption = 1              # 1 pass; 2 stop\n",
    "WeakSourceOption = 1            # 1 pass; 2 stop\n",
    "ReferemceTimeOption = 1         # 1 time value; 2 stress period, time step, relative offset\n",
    "StopOption = 2                  # 1 stop with simulation 2; extend if steady state 3; specify time\n",
    "ParticleGenerationOption = 2    # 1 automatic; 2 external file\n",
    "TimePointOption = 1             # 1 none; 2 number at fixed intervals; 3 array\n",
    "BudgetOutputOption = 3          # 1 none; 2 summary; 3 list of cells; 4 trace mode\n",
    "ZoneArrayOption = 1             # 1 none; 2 read zone array(s) \n",
    "RetardationOption = 1           # 1 none; 2 read array(s) \n",
    "AdvectiveObservationsOption = 1 # 1 none; 2 saved for all time pts 3; saved for final time pt\n",
    "\n",
    "options = [SimulationType, TrackingDirection, WeakSinkOption, WeakSourceOption, ReferemceTimeOption, \n",
    "           StopOption, ParticleGenerationOption, TimePointOption, BudgetOutputOption, ZoneArrayOption, \n",
    "           RetardationOption, AdvectiveObservationsOption]\n",
    "\n",
    "for group in zone_df:\n",
    "    print('   Write and run MODPATH for {}'.format(group))\n",
    "    \n",
    "    mpname = '{}_{}_{}'.format(fpmg.name, weight_label, group)\n",
    "    mpnf = '{}_{}_{}.mpnam'.format(fpmg.name, weight_label, group)\n",
    "    mplf = '{}_{}_{}.mplst'.format(fpmg.name, weight_label, group)\n",
    "\n",
    "    mp = fp.modpath.Modpath(modelname=mpname, modflowmodel=fpmg, dis_file=dis.file_name[0], exe_name=mp_exe_name,\n",
    "                            model_ws=model_ws, simfile_ext='mpsim', dis_unit=dis.unit_number[0])\n",
    "\n",
    "    mpsim = fp.modpath.ModpathSim(mp, mp_name_file=mpnf, \n",
    "                                  mp_list_file=mplf, \n",
    "                                  option_flags=options,\n",
    "                                  ref_time=ref_time,\n",
    "                                  cell_bd_ct=10, \n",
    "                                  bud_loc=bud_chk_dict[group].loc[:, ('Grid', 'Layer', 'Row', 'Column')].values.tolist(),\n",
    "                                  extension='mpsim')\n",
    "\n",
    "    mpbas = fp.modpath.ModpathBas(mp, hnoflo=hnoflo, hdry=hdry, \n",
    "                                  def_face_ct=1, bud_label=['RECHARGE'], def_iface=[6], \n",
    "                                  laytyp=upw.laytyp.get_value(), ibound=ibound, \n",
    "                                  prsity=por, prsityCB=0.20)    \n",
    "\n",
    "    mp.write_input()\n",
    "    success, msg = mp.run_model(silent=False, report=True)\n",
    "\n",
    "    # delete starting locations to save space--this information is now in the endpoint file\n",
    "#     if success:\n",
    "#         dst_pth = os.path.join(model_ws, '{}_{}_{}.loc'.format(fpmg.name, weight_label, group))\n",
    "#         os.remove(dst_pth)\n",
    "\n",
    "print ('   ... done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check budget\n",
    "Compare the calculated composite budget in the notebook to the cell budget output from MODPATH. We assume MODPATH computes the budget items correctly.  If the notebook and MODPATH don't match, it is likely that the model uses a stress package that has not been tested with the notebook and that applies stress in a unique way.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for group in zone_df:\n",
    "    \n",
    "    print('Checking budget for {}'.format(group))\n",
    "    budchk_df = bud_chk_dict[group]\n",
    "    \n",
    "    with open(os.path.join(model_ws, '{}_{}_{}.mplst'.format(fpmg.name, weight_label, group)), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for n, item in enumerate(lines):\n",
    "        if (('Processing Time Step' in item) & (str(kstpkper[1] + 1) in item[34:40])):\n",
    "            begin = n\n",
    "            end = len(lines)\n",
    "        elif (('Processing Time Step' in item) & (str(kstpkper[1]) in item[34:40])):\n",
    "            end = n\n",
    "\n",
    "    fl = []\n",
    "    re = []\n",
    "    for i in lines[begin:end]:\n",
    "        if 'FLOW IN' in i:\n",
    "            fl.append(np.float32(i[33:52]))\n",
    "        if  'QZ2' in i:\n",
    "            re.append(np.float32(i[48:62]))\n",
    "\n",
    "    for i in range(num_cells2budchk):\n",
    "        print('budget comparison for zero-based cell {}'.format(budchk[i]))\n",
    "\n",
    "        print('   total in from notebook = {:10.4f}'.format(budchk_df.loc[i, 'flow_sum']))\n",
    "        print('   total in from modflow  = {:10.4f}'.format(fl[i+1]))\n",
    "        print('   net notebook upper boundary flow = {:10.4f}'.format(budchk_df.loc[i, 'qz2']))\n",
    "        print('   net modflow  upper boundary flow = {:10.4f}'.format(re[i+1]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
