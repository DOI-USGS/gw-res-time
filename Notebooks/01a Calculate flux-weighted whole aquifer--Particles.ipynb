{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to get residence-time distribution (RTD) for the entire aquifer from an existing MODFLOW model. It is possible to read in any group or label from a 3D array and make RTDs for those groups. The approach is to \n",
    "* read an existing model\n",
    "* create flux-weighted particle starting locations in every cell\n",
    "* run MODPATH and read endpoints\n",
    "* fit parametric distributions to endpoints\n",
    "\n",
    "This notebook creates flux-weighted particles.  Another notebook fits parametric distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mt\n",
    "import flopy as fp\n",
    "import imeth\n",
    "import pandas as pd\n",
    "import gdal\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set user-defined variables\n",
    "\n",
    "MODFLOW and MODPATH use elapsed time and are not aware of calendar time. To place MODFLOW/MODPATH elapsed time on the calendar, two calendar dates were specified at the top of the notebook: the beginning of the first stress period (`mf_start_date`) and when particles are to be released (`mp_release_date`). The latter date could be used in many ways, for example to represent a sampling date, or it could be looped over to create a time-lapse set of ages. \n",
    "\n",
    "`num_surf_layers` is an arbitrary layer number on which to divide the model domain for calculating RTDs. For example, in glacial aquifers it could represent the layer number of the bottom of unconsolidated deposits. In that case, anything below this layer could be considered bedrock.\n",
    "\n",
    "`num_depth_groups` is an arbitrary number of equally groups starting from the water table to the bottom of the lowest model layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through home directory to get list of name files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2020' \n",
    "\n",
    "num_surf_layers = 3\n",
    "num_depth_groups = 5\n",
    "\n",
    "por = 0.20\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    mod_list.append(mod)\n",
    "                    dir_list.append(dirpath)\n",
    "                    i += 1\n",
    "print('    {} models read'.format(i))\n",
    "\n",
    "model_area = Dropdown(\n",
    "    options=mod_list,\n",
    "    description='Model:',\n",
    "    background_color='cyan',\n",
    "    border_color='black',\n",
    "    border_width=2)\n",
    "display(model_area)\n",
    "\n",
    "with open('dir_list.txt', 'w') as f:\n",
    "    for i in dir_list:\n",
    "        f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create names and path for model workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedures in this notebook can be run from the notebook or from a batch file by downloading the notebook as a Python script and uncommenting the following code and commenting out the following block. The remainder of the script has to be indented to be included in the loop.  This may require familiarity with Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for pth in dir_list:\n",
    "#     model = os.path.normpath(pth).split(os.sep)[2]\n",
    "#     model_ws = [item for item in dir_list if model in item][0]\n",
    "#     nam_file = '{}.nam'.format(model)\n",
    "#     print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model_area.value\n",
    "model_ws = [item for item in dir_list if model in item][0]\n",
    "nam_file = '{}.nam'.format(model)\n",
    "print(\"working model is {}\".format(model_ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('Reading model information')\n",
    "\n",
    "fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                               load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "dis = fpmg.get_package('DIS')\n",
    "bas = fpmg.get_package('BAS6')\n",
    "upw = fpmg.get_package('UPW')\n",
    "oc = fpmg.get_package('OC')\n",
    "\n",
    "delr = dis.delr\n",
    "delc = dis.delc\n",
    "nlay = dis.nlay\n",
    "nrow = dis.nrow\n",
    "ncol = dis.ncol\n",
    "bot = dis.getbotm()\n",
    "top = dis.gettop()\n",
    "\n",
    "hnoflo = bas.hnoflo\n",
    "ibound = np.asarray(bas.ibound.get_value())\n",
    "hdry = upw.hdry\n",
    "\n",
    "print ('   ... done') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FloPy loads MODFLOW packages but not their name-file unit numbers, so these have to be read separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, fpmg.namefile)\n",
    "name_file_df = pd.read_table(src, header=None, comment='#', delim_whitespace=True, \n",
    "              names=['package', 'unit', 'filename', 'type'])\n",
    "\n",
    "name_file_df['package'] = name_file_df.package.str.lower()\n",
    "name_file_df.set_index('unit', inplace=True)\n",
    "\n",
    "head_file_name = name_file_df.loc[oc.iuhead, 'filename']\n",
    "bud_file_name = name_file_df.loc[oc.get_budgetunit(), 'filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of time in MODFLOW/MODPATH\n",
    "\n",
    "There are several time-related definitons used in MODPATH.\n",
    "* `simulation time` is the elapsed time in model time units from the beginning of the first stress period\n",
    "* `reference time` is an arbitrary value of `simulation time` that is between the beginning and ending of `simulation time`\n",
    "* `tracking time` is the elapsed time relative to `reference time`. It is always positive regardless of whether particles are tracked forward or backward\n",
    "* `release time` is when a particle is released and is specified in `tracking time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days, so enter conversion to days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0\n",
    "\n",
    "# convert string representation of dates into Python datetime objects\n",
    "mf_start_date = dt.datetime.strptime(mf_start_date_str , '%m/%d/%Y')\n",
    "mp_release_date = dt.datetime.strptime(mp_release_date_str , '%m/%d/%Y')\n",
    "\n",
    "# convert simulation time to days from the units specified in the MODFLOW DIS file\n",
    "sim_time = np.append(0, dis.get_totim())\n",
    "sim_time /= time_dict[dis.itmuni]\n",
    "\n",
    "# make a list of simulation time formatted as calendar dates\n",
    "date_list = [mf_start_date + dt.timedelta(days = item) for item in sim_time]\n",
    "\n",
    "# reference time and date are set to the end of the last stress period\n",
    "ref_time = sim_time[-1]\n",
    "ref_date = date_list[-1]\n",
    "\n",
    "# release time is calculated in tracking time (for particle release) and \n",
    "# in simulation time (for identifying head and budget components)\n",
    "release_time_trk = np.abs((ref_date - mp_release_date).days)\n",
    "release_time_sim = (mp_release_date - mf_start_date).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read budget file records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, bud_file_name)\n",
    "bud_obj = fp.utils.CellBudgetFile(src)\n",
    "all_bud_df = pd.DataFrame(bud_obj.recordarray)\n",
    "\n",
    "# convert to zero base\n",
    "all_bud_df['kper'] = all_bud_df['kper'] - 1\n",
    "all_bud_df['kstp'] = all_bud_df['kstp'] - 1\n",
    "\n",
    "# add calendar date (not used at this time)\n",
    "all_bud_df['date'] = mf_start_date + pd.to_timedelta(all_bud_df.totim, unit='days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify time step and stress period for particle release\n",
    "\n",
    "* read all stress periods and time steps that were preserved in the budget file\n",
    "* find the largest (latest) stress period and time step that include the mp_release_date\n",
    "* make a subset of all the budget records from the specified period and step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# group by period and step\n",
    "kdf = all_bud_df.groupby(['kper', 'kstp']).median()\n",
    "\n",
    "# find the latest group index that includes the release date\n",
    "idx = kdf.loc[(kdf.totim >= release_time_sim).idxmax(), :].name\n",
    "\n",
    "# switch period and step \n",
    "kstpkper = tuple(item for item in idx[-1::-1])\n",
    "\n",
    "# extract the budget records for the specified period and step\n",
    "bud_df = all_bud_df.query('kstp=={} and kper=={}'.format(*kstpkper)).copy()\n",
    "\n",
    "bud_df.loc[:, 'per_num'] = bud_df.totim.factorize()[0]\n",
    "num_rec = bud_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract specified flows from MODFLOW budget\n",
    "\n",
    "Get recharge at top model surface (recharge package only at this time) and flow across the bottom of layer = num_surf_layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if b'        RECHARGE' in bud_df.text.values:\n",
    "    # probably should make this so that recharge is summed from the highest active cell\n",
    "    rch = bud_obj.get_data(text='RECHARGE', kstpkper=kstpkper, full3D=True)\n",
    "    recharge_vol = rch[0].sum()  \n",
    "else:\n",
    "    print('no recharge')\n",
    "# This assumes all recharge is from RCH package. Should add a check for UZF package & concat them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if num_surf_layers <= nlay:  \n",
    "    flf = bud_obj.get_data(text='FLOW LOWER FACE', kstpkper=kstpkper, full3D=True)\n",
    "    flow2rock = flf[0][num_surf_layers - 1, :, :]\n",
    "    bedrock_recharge_vol = flow2rock[flow2rock > 0].sum()\n",
    "    bed_frac = bedrock_recharge_vol / recharge_vol\n",
    "else:\n",
    "    print('invalid num_surf_layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read head file\n",
    "The head file is used limit particle placement to the saturated part of each cell and to identify dry cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src = os.path.join(model_ws, head_file_name)\n",
    "hd_obj = fp.utils.HeadFile(src)\n",
    "head_df = pd.DataFrame(hd_obj.recordarray)\n",
    "\n",
    "heads = hd_obj.get_data(kstpkper=kstpkper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate saturated thickness and volume for each cell.\n",
    "* create 3D model cell boundary grid\n",
    "* saturated top in cell is minimum of head or cell top\n",
    "* saturated thickness is the distance between the saturated top and cell bottom\n",
    "* if the cell is dry or inactive, the saturated thickness is zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a 3D array of layer boundaries\n",
    "grid = np.zeros((nlay+1, nrow, ncol))\n",
    "grid[0, :, :] = top\n",
    "grid[1:, :, :] = bot\n",
    "\n",
    "# tmp is the minimum of the head and cell top \n",
    "tmp = np.minimum(heads, grid[:-1, :, :])\n",
    "\n",
    "# the saturated thickness is first estimated to be the difference between tmp and the cell bottom\n",
    "sat_thk_cell = (tmp - grid[1:, :, :]) \n",
    "\n",
    "# sat_thk_cell < 0 means the head is below the bottom of the cell; these are set to zero\n",
    "sat_thk_cell[sat_thk_cell < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mean exponential age \n",
    "\n",
    "Based on simulated recharge volumteric rate and simulated aquifer volume. Calculations are for the entire model (total) and for layers above and below the layer specified at the top of the notebook as `num_surf_layers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create grid cell dimension arrays\n",
    "delc_ar, dum, delr_ar = np.meshgrid(delc, np.arange(nlay), delr)\n",
    "\n",
    "# saturated volume of each cell\n",
    "sat_vol_cell = sat_thk_cell * delc_ar * delr_ar\n",
    "\n",
    "# sum totals\n",
    "total_sat_vol = sat_vol_cell.sum()\n",
    "total_sat_vol_glac = sat_vol_cell[0:num_surf_layers, :, :].sum()\n",
    "total_sat_vol_bedr = sat_vol_cell[num_surf_layers:, :, :].sum()\n",
    "\n",
    "tau_glacial = total_sat_vol_glac * por / recharge_vol / 365.25\n",
    "tau_bedrock = total_sat_vol_bedr * por / bedrock_recharge_vol  / 365.25\n",
    "tau_total = total_sat_vol * por / recharge_vol /  365.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('tau total = {:8.0f} years'.format(tau_total))\n",
    "print('tau above = {:8.0f} years'.format(tau_glacial))\n",
    "print('tau below = {:8.0f} years'.format(tau_bedrock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dst = os.path.join(model_ws, 'tau.txt')\n",
    "with open(dst, 'w') as f:\n",
    "    line = 'Mean exponential age in glacial is {0:0.6f} years\\n'.format(tau_glacial)\n",
    "    f.write(line)\n",
    "    line = 'Mean exponential age in bedrock is {0:0.6f} years\\n'.format(tau_bedrock)\n",
    "    f.write(line)\n",
    "    line = 'Mean exponential age in total is {0:0.6f} years\\n'.format(tau_total)\n",
    "    f.write(line)\n",
    "    line = 'Inflow to bedrock is {0:0.0f} cubic meters per day\\n'.format(bedrock_recharge_vol)\n",
    "    f.write(line)\n",
    "    line = 'Inflow to bedrock is {0:0.3f} of total recharge\\n'.format(bed_frac)\n",
    "    f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MODPATH input files and run MODPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate inflow into each cell\n",
    "The number of particles in each cell is in proportion to the flux into the cell. Particle locations within a cell are generated randomly. The proportion constant is calculated from the desired total number of particles. Number of particles per cell is proportional to the flow into the cell such that the total number of particles = `t_num_parts`, in this case 2 million. \n",
    "\n",
    "MODFLOW includes a variable called `imeth` in the budget file. `imeth` is used to specify the format in which the budget data are stored. Functions for reading `imeth` for each of the data formats are defined in the module imeth.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flow_times = bud_df.totim.unique()\n",
    "nt = bud_df.per_num.nunique()\n",
    "\n",
    "rxc = dis.nrow * dis.ncol\n",
    "nn = dis.nlay * rxc\n",
    "\n",
    "im = imeth.imeth(nlay, nrow, ncol)\n",
    "\n",
    "qx1 = np.zeros((nt, nn))\n",
    "qx2 = np.zeros_like(qx1)\n",
    "qy1 = np.zeros_like(qx1)\n",
    "qy2 = np.zeros_like(qx1)\n",
    "qz1 = np.zeros_like(qx1)\n",
    "qz2 = np.zeros_like(qx1)\n",
    "storage = np.zeros_like(qx1)\n",
    "\n",
    "bound_flow = np.zeros((nn, 7))\n",
    "int_flow_right = np.zeros((nn))\n",
    "int_flow_left = np.zeros((nn))\n",
    "int_flow_front = np.zeros((nn))\n",
    "int_flow_back = np.zeros((nn))\n",
    "int_flow_lower = np.zeros((nn))\n",
    "int_flow_top = np.zeros((nn))\n",
    "\n",
    "for i, rec in bud_df.iterrows():\n",
    "\n",
    "    BUFF = bud_obj.get_record(i)\n",
    "    \n",
    "    internal_flow_list = [b'   CONSTANT HEAD', b'FLOW RIGHT FACE ', b'FLOW FRONT FACE ', b'FLOW LOWER FACE ', b'STORAGE']\n",
    "\n",
    "    if rec.text in internal_flow_list:\n",
    "        if b'   CONSTANT HEAD' in rec.text:\n",
    "            bound_flow += im.imeth2(BUFF)\n",
    "        elif b'FLOW RIGHT FACE ' in rec.text:\n",
    "            int_flow_right = im.imeth1(BUFF)\n",
    "            int_flow_left = np.roll(int_flow_right, 1)\n",
    "        elif b'FLOW FRONT FACE ' in rec.text:\n",
    "            int_flow_front = im.imeth1(BUFF)\n",
    "            int_flow_back = np.roll(int_flow_front, ncol)\n",
    "        elif b'FLOW LOWER FACE ' in rec.text:\n",
    "            int_flow_lower = im.imeth1(BUFF)\n",
    "            int_flow_top = np.roll(int_flow_lower, rxc)\n",
    "        elif b'STORAGE' in rec.text:\n",
    "            bound_flow[: , 0] += im.imeth1(BUFF)\n",
    "        else:\n",
    "            print('Unrecognized budget type')\n",
    "\n",
    "    if rec.text not in internal_flow_list:\n",
    "        if rec.imeth == 1:\n",
    "            bound_flow[:, 0] += im.imeth1(BUFF)\n",
    "        elif rec.imeth == 2:\n",
    "            bound_flow[:, 0] += im.imeth2(BUFF)\n",
    "        elif rec.imeth == 3:\n",
    "            bound_flow += im.imeth3(BUFF)\n",
    "        elif rec.imeth == 4:\n",
    "            bound_flow += im.imeth4(BUFF)\n",
    "        elif rec.imeth == 5:\n",
    "            bound_flow += im.imeth5(BUFF)\n",
    "        else:\n",
    "            print('Unrecognized budget type')\n",
    "\n",
    "    storage[rec.per_num , :] += bound_flow[:, 0]\n",
    "\n",
    "    qx1[rec.per_num , :] = int_flow_left + bound_flow[:, 1]\n",
    "    qx2[rec.per_num , :] = int_flow_right - bound_flow[:, 2]\n",
    "\n",
    "    qy1[rec.per_num , :] = -int_flow_front + bound_flow[:, 3]\n",
    "    qy2[rec.per_num , :] = -int_flow_back - bound_flow[:, 4]\n",
    "\n",
    "    qz1[rec.per_num , :] = -int_flow_lower + bound_flow[:, 5]\n",
    "    qz2[rec.per_num , :] = -int_flow_top - bound_flow[:, 6]\n",
    "\n",
    "qin1 = np.where(qx1 > 0, qx1, 0)\n",
    "qin2 = np.where(qx2 < 0, -qx2, 0)\n",
    "qin3 = np.where(qy1 > 0, qy1, 0)\n",
    "qin4 = np.where(qy2 < 0, -qy2, 0)\n",
    "qin5 = np.where(qz1 > 0, qz1, 0)\n",
    "qin6 = np.where(qz2 < 0, -qz2, 0)\n",
    "\n",
    "flow_sum = np.sum((qin1, qin2, qin3, qin4, qin5, qin6), axis=0)\n",
    "\n",
    "# set the flow to zero for cells that went dry during the simulation and also for isolated cells\n",
    "flow_sum[0, heads.ravel() == hdry] = 0\n",
    "# flow_sum[heads.ravel() > 1.E+29] = 0\n",
    "\n",
    "print ('   ... done'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat cell coordinates for the number of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now hardwired to first stress period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_num_parts =  2.0E+06\n",
    "flow_per_period = flow_sum[0, :]\n",
    "f = t_num_parts / flow_per_period.sum()\n",
    "\n",
    "parts_per_cell = np.rint( flow_per_period * f ).astype( np.int32 )\n",
    "\n",
    "l, r, c = np.indices(( nlay, nrow, ncol ))\n",
    "\n",
    "lrep = np.repeat( l, parts_per_cell.ravel() )\n",
    "rrep = np.repeat( r, parts_per_cell.ravel() )\n",
    "crep = np.repeat( c, parts_per_cell.ravel() )\n",
    "num_parts = lrep.shape[0]\n",
    "\n",
    "print(num_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Min  number of particles per active cell = {:10.0f}'.format(parts_per_cell[ibound.ravel() != 0].min()))\n",
    "print('Mean number of particles per active cell = {:10.0f}'.format(parts_per_cell[ibound.ravel() != 0].mean()))\n",
    "print('Max  number of particles per active cell = {:10.0f}'.format(parts_per_cell[ibound.ravel() != 0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit vertical particle placement to the saturated part of each cell\n",
    "MODPATH wants particle locations as the layer, row, column (which we now have) plus the relative cell coordinates within each cell over (0, 1). In this application relative cell coordinates are generated randomly. In partially saturated cells, the random particle location is scaled to the saturated thickness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate random relative coordinates within a cell in 3D\n",
    "cell_coords = np.random.rand( num_parts, 3 )\n",
    "\n",
    "# calculate the fraction of saturation; unsaturated = 0, partially saturated 0 to 1, fully saturated = 1\n",
    "vfrac = sat_thk_cell / -np.diff(grid, axis=0)\n",
    "\n",
    "# replace z coordinate with random number scaled to vfrac\n",
    "cell_coords[:, 2] = np.random.rand( num_parts ) * np.repeat( vfrac, parts_per_cell.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign depth related group number\n",
    "\n",
    "Particle groups are assigned based on the relative position. Other approaches could be substitued.  They must be integers. Zone numbers can be read into the label variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# percent_thk_lay = sat_thk_cell[:num_surf_layers, :, :] / sat_thk_cell[:num_surf_layers, :, :].sum(axis=0)\n",
    "# percent_thk_lay_cum = 1 - np.cumsum(percent_thk_lay, axis=0)\n",
    "\n",
    "# z_cell = cell_coords[:, 2]\n",
    "# rel_z_pos = percent_thk_lay_cum[lrep, rrep, crep] + z_cell * percent_thk_lay[lrep, rrep, crep]\n",
    "# group = np.digitize(1 - rel_z_pos, np.linspace(0, 1, num_depth_groups + 1))\n",
    "group = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## Read zone array to use as particle label. \n",
    "\n",
    "To Do : Add code to read zone array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zones = np.readtxt()\n",
    "label = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create particle array\n",
    "Particles locations are assembled into an array in MODPATH format. Then sort them by group. MODPATH seems to like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = 1\n",
    "\n",
    "particles = np.zeros( ( num_parts, 11 ) )\n",
    "particles[:, 0] = np.arange( 1, num_parts + 1 )\n",
    "particles[:, 1] = group\n",
    "particles[:, 2] = grid\n",
    "particles[:, 3] = lrep + 1\n",
    "particles[:, 4] = rrep + 1\n",
    "particles[:, 5] = crep + 1\n",
    "particles[:, 6:9] = cell_coords\n",
    "particles[:, 9] = release_time_trk\n",
    "particles[:, 10] = label\n",
    "\n",
    "# sort_index = np.argsort(group)\n",
    "# particles = particles[sort_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write particle starting locations\n",
    "The external particle starting locations file is written, including header information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('   Write starting locations for {} particles'.format(particles.shape[0]))\n",
    "\n",
    "PartStartForm = '%6d %6d %3d %3d %3d %3d %12.9f %12.9f %12.9f %12.9e %15.3f'\n",
    "line = '{:5d}\\n{:5d}\\n'.format(1, num_depth_groups + 1)\n",
    "for item in range(1, num_depth_groups + 2):\n",
    "    line = line + 'group_{}\\n'.format(item)\n",
    "    npart = ((particles[:, 1]) == item).sum()\n",
    "    if item == (num_depth_groups + 1):\n",
    "        line = line + '{:6d}'.format(npart)\n",
    "    else:\n",
    "        line = line + '{:6d}\\n'.format(npart)\n",
    "dst_pth = os.path.join(model_ws, '{}_flux.loc'.format(fpmg.name))\n",
    "np.savetxt(dst_pth, particles, delimiter=' ', fmt=PartStartForm, header=line, comments='')\n",
    "\n",
    "print ('   ... done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MODPATH and read endpoint information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get random cells to check budget computations\n",
    "Select 10 random active cells to check cell budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(2909591)\n",
    "A = (particles[:, 3:6] - 1)\n",
    "A = A[prng.choice(A.shape[0], 10, replace=False), :]\n",
    "budchk = np.ones((10, 4))\n",
    "budchk[:, 1:] = A\n",
    "budchk = budchk.astype(np.int32())\n",
    "budchk = budchk.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MODPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('   Write and run MODPATH')\n",
    "\n",
    "# prepare Modpath files   \n",
    "SimulationType = 1              # 1 endpoint; 2 pathline; 3 timeseries\n",
    "TrackingDirection = 2           # 1 forward; 2 backward\n",
    "WeakSinkOption = 1              # 1 pass; 2 stop\n",
    "WeakSourceOption = 1            # 1 pass; 2 stop\n",
    "ReferemceTimeOption = 2         # 1 time value; 2 stress period, time step, relative offset\n",
    "StopOption = 2                  # 1 stop with simulation 2; extend if steady state 3; specify time\n",
    "ParticleGenerationOption = 2    # 1 automatic; 2 external file\n",
    "TimePointOption = 1             # 1 none; 2 number at fixed intervals; 3 array\n",
    "BudgetOutputOption = 3          # 1 none; 2 summary; 3 list of cells; 4 trace mode\n",
    "ZoneArrayOption = 1             # 1 none; 2 read zone array(s) \n",
    "RetardationOption = 1           # 1 none; 2 read array(s) \n",
    "AdvectiveObservationsOption = 1 # 1 none; 2 saved for all time pts 3; saved for final time pt\n",
    "\n",
    "options = [SimulationType, TrackingDirection, WeakSinkOption, WeakSourceOption, ReferemceTimeOption, \n",
    "           StopOption, ParticleGenerationOption, TimePointOption, BudgetOutputOption, ZoneArrayOption, \n",
    "           RetardationOption, AdvectiveObservationsOption]\n",
    "\n",
    "mpname = '{}_flux'.format(fpmg.name)\n",
    "mp = fp.modpath.Modpath(modelname=mpname, modflowmodel=fpmg, dis_file=dis.file_name[0], exe_name=mp_exe_name,\n",
    "                        model_ws=model_ws, simfile_ext='mpsim', dis_unit=dis.unit_number[0])\n",
    "\n",
    "mpnf = '{}.mpnam'.format(fpmg.name)\n",
    "mplf = '{}.mplst'.format(fpmg.name)\n",
    "\n",
    "mpsim = fp.modpath.ModpathSim(mp, mp_name_file=mpnf, \n",
    "                              mp_list_file=mplf, \n",
    "                              option_flags=options,\n",
    "#                               ref_time=ref_time,\n",
    "                              ref_time_per_stp=[0, 0, 1.0],\n",
    "                              cell_bd_ct=10, \n",
    "                              bud_loc=budchk,\n",
    "                              extension='mpsim')\n",
    "\n",
    "mpbas = fp.modpath.ModpathBas(mp, hnoflo=hnoflo, hdry=hdry, \n",
    "                              def_face_ct=2, bud_label=['RECHARGE', 'DRAIN'], def_iface=[6, 6], \n",
    "                              laytyp=upw.laytyp.get_value(), ibound=ibound, \n",
    "                              prsity=por, prsityCB=0.20)    \n",
    "\n",
    "mp.write_input()\n",
    "success, msg = mp.run_model(silent=False, report=True)\n",
    "\n",
    "# delete starting locations to save space--this information is now in the endpoint file\n",
    "\n",
    "dst_pth = os.path.join(model_ws, '{}_flux.loc'.format(fpmg.name))\n",
    "os.remove(dst_pth)\n",
    "\n",
    "print ('   ... done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check budget\n",
    "Compare the calculated composite budget in the notebook to the cell budget output from MODPATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(model_ws, '{}.mplst'.format(mpname)), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "fl = []\n",
    "re = []\n",
    "for i in lines:\n",
    "    if 'FLOW IN' in i:\n",
    "        fl.append(np.float32(i[33:52]))\n",
    "    if  'QZ2' in i:\n",
    "        re.append(np.float32(i[48:62]))\n",
    "\n",
    "def seq(item):\n",
    "    return item[1] * rxc + item[2] * ncol + item[3] \n",
    "seq_arr = np.array([seq(item) for item in budchk])\n",
    "\n",
    "for k, i in enumerate(seq_arr):\n",
    "    print('notebook budget for zero-based cell cell {}'.format(budchk[k]))\n",
    "    \n",
    "    print('   qx1 = {:10.4f}  qx2 = {:10.4f}'.format(qx1[0, i], qx2[0, i]))\n",
    "    print('   qy1 = {:10.4f}  qy2 = {:10.4f}'.format(qy1[0, i], qy2[0, i]))\n",
    "    print('   qz1 = {:10.4f}  qz2 = {:10.4f}'.format(qz1[0, i], qz2[0, i]))\n",
    "    print('total in from notebook = {:10.4f}'.format(flow_sum[0, i]))\n",
    "    print('total in from modflow  = {:10.4f}'.format(fl[k+1]))\n",
    "    print('net notebook total boundary inflow = {:10.4f}'.format(bound_flow[i, :].sum()))\n",
    "    print('net notebook upper boundary flow = {:10.4f}'.format(qz2[0, i]))\n",
    "    print('net modflow  upper boundary flow = {:10.4f}'.format(re[k+1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
